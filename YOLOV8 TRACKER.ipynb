{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6256b42b5a84c65bcc127153ebcee10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aca7803fb64144888e6c98382c7547cd",
              "IPY_MODEL_2acb266e7dde48dd980bf180d8031e61",
              "IPY_MODEL_4360b481223e4312a32d60e3d3cba2ae"
            ],
            "layout": "IPY_MODEL_359d550c0725456d90e92a0fd92eadd9"
          }
        },
        "aca7803fb64144888e6c98382c7547cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42d0af8a6a8a424d81fb6272cc1b337f",
            "placeholder": "​",
            "style": "IPY_MODEL_97ea2e8cd6244f04ac7d0c28946a2da3",
            "value": "100%"
          }
        },
        "2acb266e7dde48dd980bf180d8031e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4f90015c42e4d30a183dfd207d3db6d",
            "max": 136867539,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00b0d467683b44c9bac4342778558b6f",
            "value": 136867539
          }
        },
        "4360b481223e4312a32d60e3d3cba2ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_363ca4848795447fa8c05aae517e3079",
            "placeholder": "​",
            "style": "IPY_MODEL_06b3086c7fb44f5891de3dc7e44c5acf",
            "value": " 131M/131M [00:00&lt;00:00, 287MB/s]"
          }
        },
        "359d550c0725456d90e92a0fd92eadd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42d0af8a6a8a424d81fb6272cc1b337f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97ea2e8cd6244f04ac7d0c28946a2da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4f90015c42e4d30a183dfd207d3db6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00b0d467683b44c9bac4342778558b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "363ca4848795447fa8c05aae517e3079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06b3086c7fb44f5891de3dc7e44c5acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f6de397474642f68b203a9017307831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6f876391afb4e319e70c05c9c4b82c6",
              "IPY_MODEL_931fab634a0d471f91690170bc27d3e0",
              "IPY_MODEL_7223c71f5ee84c4683b8cf662acc9ea5"
            ],
            "layout": "IPY_MODEL_cafeac3373764987951fd62809899adc"
          }
        },
        "d6f876391afb4e319e70c05c9c4b82c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e88dac2a9b643c9853ca99a882a2e73",
            "placeholder": "​",
            "style": "IPY_MODEL_ce0ced0d52634a7c8e0727bd3e04bb64",
            "value": "100%"
          }
        },
        "931fab634a0d471f91690170bc27d3e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae7a7838ccad4db2a3ca9ab6b19743f7",
            "max": 4349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7fcef851b2fa42299056721101e28aa1",
            "value": 4349
          }
        },
        "7223c71f5ee84c4683b8cf662acc9ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58b4827fb6ef4246943cf5ed46a7efe4",
            "placeholder": "​",
            "style": "IPY_MODEL_0a8a6a9e4cba4e16aee80f43b993e61d",
            "value": " 4349/4349 [07:35&lt;00:00, 14.67it/s]"
          }
        },
        "cafeac3373764987951fd62809899adc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e88dac2a9b643c9853ca99a882a2e73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce0ced0d52634a7c8e0727bd3e04bb64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae7a7838ccad4db2a3ca9ab6b19743f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fcef851b2fa42299056721101e28aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58b4827fb6ef4246943cf5ed46a7efe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a8a6a9e4cba4e16aee80f43b993e61d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinav70291/OBJECT-DETECTION-USING-YOLOV8/blob/main/YOLOV8%20TRACKER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before you start\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ],
      "metadata": {
        "id": "zCVyYjLXofL9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4okzdHlKMaj",
        "outputId": "395df39e-6049-482e-c412-e314197c50de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 15 20:56:09 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P0    27W /  70W |   1497MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "984J4pv4K2D-",
        "outputId": "a85a1642-f821-4230-de75-02594f7e9d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ByteTrack/ByteTrack\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_VIDEO_PATH = f\"/content/drive/MyDrive/people and vehicle count/y2mate.com - Revisiting the Pedestrian Crush on NYCs 34th Street 10 Years Later Still Chaos_1080p.mp4\"\n",
        "     "
      ],
      "metadata": {
        "id": "lCmCRjz0R0Bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install YOLOv8\n",
        "version **YOLOv8.0.17**.\n"
      ],
      "metadata": {
        "id": "lAFba4GkombF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pip install method (recommended)\n",
        "\n",
        "!pip install ultralytics\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "IGckxTNGLKDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c6401f-ae59-4aab-9f31-1f95019d8531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.53 🚀 Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 26.4/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install ByteTrack\n",
        "\n",
        "[ByteTrack](https://github.com/ifzhang/ByteTrack) is great tracker but a bit poorly packaged. We need to jump through some fire hoops to make it work in tandem with [YOLOv8](https://github.com/ultralytics/ultralytics)."
      ],
      "metadata": {
        "id": "0e1ilpTlovJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "%cd {HOME}/ByteTrack\n",
        "\n",
        "# workaround related to https://github.com/roboflow/notebooks/issues/80\n",
        "!sed -i 's/onnx==1.8.1/onnx==1.9.0/g' requirements.txt\n",
        "\n",
        "!pip3 install -q -r requirements.txt\n",
        "!python3 setup.py -q develop\n",
        "!pip install -q cython_bbox\n",
        "!pip install -q onemetric\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append(f\"{HOME}/ByteTrack\")\n",
        "\n",
        "\n",
        "import yolox\n",
        "print(\"yolox.__version__:\", yolox.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KdBkOflo2xY",
        "outputId": "bd178203-9bae-41fe-e386-5d9456cc03a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yolox.__version__: 0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "from onemetric.cv.utils.iou import box_iou_batch\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.25\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False"
      ],
      "metadata": {
        "id": "rwg-lY49o7Sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Roboflow Supervision"
      ],
      "metadata": {
        "id": "_kSHFj8uQ9qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision==0.1.0\n",
        "\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import supervision\n",
        "print(\"supervision.__version__:\", supervision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d60yX_PFQ9A2",
        "outputId": "9d7e856a-f539-42bd-9cd3-fef1cf39a80f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "supervision.__version__: 0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from supervision.draw.color import ColorPalette\n",
        "from supervision.geometry.dataclasses import Point\n",
        "from supervision.video.dataclasses import VideoInfo\n",
        "from supervision.video.source import get_video_frames_generator\n",
        "from supervision.video.sink import VideoSink\n",
        "from supervision.notebook.utils import show_frame_in_notebook\n",
        "from supervision.tools.detections import Detections, BoxAnnotator\n",
        "from supervision.tools.line_counter import LineCounter, LineCounterAnnotator"
      ],
      "metadata": {
        "id": "7YDohOpMTWH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tracking utils\n",
        "\n",
        "we have to manually match the bounding boxes coming from our model with those created by the tracker."
      ],
      "metadata": {
        "id": "mPdB-v_hWxBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# converts Detections into format that can be consumed by match_detections_with_tracks function\n",
        "def detections2boxes(detections: Detections) -> np.ndarray:\n",
        "    return np.hstack((\n",
        "        detections.xyxy,\n",
        "        detections.confidence[:, np.newaxis]\n",
        "    ))\n",
        "\n",
        "\n",
        "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
        "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
        "    return np.array([\n",
        "        track.tlbr\n",
        "        for track\n",
        "        in tracks\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# matches our bounding boxes with predictions\n",
        "def match_detections_with_tracks(\n",
        "    detections: Detections, \n",
        "    tracks: List[STrack]\n",
        ") -> Detections:\n",
        "    if not np.any(detections.xyxy) or len(tracks) == 0:\n",
        "        return np.empty((0,))\n",
        "\n",
        "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
        "    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "    \n",
        "    tracker_ids = [None] * len(detections)\n",
        "    \n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            tracker_ids[detection_index] = tracks[tracker_index].track_id\n",
        "\n",
        "    return tracker_ids"
      ],
      "metadata": {
        "id": "SE0G6LvFAXlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load pre-trained YOLOv8 model"
      ],
      "metadata": {
        "id": "c_417m4g9XVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# settings\n",
        "MODEL = \"yolov8x.pt\""
      ],
      "metadata": {
        "id": "m3FMq5FcUsRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(MODEL)\n",
        "model.fuse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "e6256b42b5a84c65bcc127153ebcee10",
            "aca7803fb64144888e6c98382c7547cd",
            "2acb266e7dde48dd980bf180d8031e61",
            "4360b481223e4312a32d60e3d3cba2ae",
            "359d550c0725456d90e92a0fd92eadd9",
            "42d0af8a6a8a424d81fb6272cc1b337f",
            "97ea2e8cd6244f04ac7d0c28946a2da3",
            "e4f90015c42e4d30a183dfd207d3db6d",
            "00b0d467683b44c9bac4342778558b6f",
            "363ca4848795447fa8c05aae517e3079",
            "06b3086c7fb44f5891de3dc7e44c5acf"
          ]
        },
        "id": "KFCV_2TR9eo_",
        "outputId": "7f56d943-8618-47a8-fb60-74faa4d175a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt to yolov8x.pt...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/131M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6256b42b5a84c65bcc127153ebcee10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv8x summary (fused): 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict and annotate single frame"
      ],
      "metadata": {
        "id": "6to6MgPmTnCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dict maping class_id to class_name\n",
        "CLASS_NAMES_DICT = model.model.names\n",
        "# class_ids of interest -person, bicycle,  car, motorcycle, bus and truck\n",
        "CLASS_ID = [0,1,2, 3, 5, 7]"
      ],
      "metadata": {
        "id": "yKuDnOIxsN6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create frame generator\n",
        "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "# create instance of BoxAnnotator\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
        "# acquire first video frame\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "# model prediction on single frame and conversion to supervision Detections\n",
        "results = model(frame)\n",
        "detections = Detections(\n",
        "    xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "    confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "    class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        ")\n",
        "# format custom labels\n",
        "labels = [\n",
        "    f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "    for _, confidence, class_id, tracker_id\n",
        "    in detections\n",
        "]\n",
        "# annotate and display frame\n",
        "frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
        "\n",
        "%matplotlib inline\n",
        "show_frame_in_notebook(frame, (16, 16))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "hZQsgCa0cFvH",
        "outputId": "080f2324-071d-4eb8-b688-c86ec18924a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 384x640 (no detections), 57.0ms\n",
            "Speed: 0.4ms preprocess, 57.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x1152 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict and annotate whole video "
      ],
      "metadata": {
        "id": "3ZbGmYfiT0EV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# settings\n",
        "LINE_START = Point(50, 1500)\n",
        "LINE_END = Point(3840-50, 1500)\n",
        "\n",
        "TARGET_VIDEO_PATH = f\"/content/drive/MyDrive/people and vehicle count/vehicle&people-counting-result.mp4\""
      ],
      "metadata": {
        "id": "MjP8Pn10XuJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VideoInfo.from_video_path(SOURCE_VIDEO_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3btq7JavXknU",
        "outputId": "8bec0c55-26f6-44da-f19a-1533f48af812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VideoInfo(width=1920, height=1080, fps=29, total_frames=4349)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "# create BYTETracker instance\n",
        "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
        "# create VideoInfo instance\n",
        "video_info = VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "# create frame generator\n",
        "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "# create LineCounter instance\n",
        "line_counter = LineCounter(start=LINE_START, end=LINE_END)\n",
        "# create instance of BoxAnnotator and LineCounterAnnotator\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
        "line_annotator = LineCounterAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# open target video file\n",
        "with VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n",
        "    # loop over video frames\n",
        "    for frame in tqdm(generator, total=video_info.total_frames):\n",
        "        # model prediction on single frame and conversion to supervision Detections\n",
        "        results = model(frame)\n",
        "        detections = Detections(\n",
        "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "            class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "        )\n",
        "        # filtering out detections with unwanted classes\n",
        "        mask = np.array([class_id in CLASS_ID for class_id in detections.class_id], dtype=bool)\n",
        "        detections.filter(mask=mask, inplace=True)\n",
        "        # tracking detections\n",
        "        tracks = byte_tracker.update(\n",
        "            output_results=detections2boxes(detections=detections),\n",
        "            img_info=frame.shape,\n",
        "            img_size=frame.shape\n",
        "        )\n",
        "        tracker_id = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
        "        detections.tracker_id = np.array(tracker_id)\n",
        "        # filtering out detections without trackers\n",
        "        mask = np.array([tracker_id is not None for tracker_id in detections.tracker_id], dtype=bool)\n",
        "        detections.filter(mask=mask, inplace=True)\n",
        "        # format custom labels\n",
        "        labels = [\n",
        "            f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "            for _, confidence, class_id, tracker_id\n",
        "            in detections\n",
        "        ]\n",
        "        # updating line counter\n",
        "        line_counter.update(detections=detections)\n",
        "        # annotate and display frame\n",
        "        frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
        "        line_annotator.annotate(frame=frame, line_counter=line_counter)\n",
        "        sink.write_frame(frame)"
      ],
      "metadata": {
        "id": "Q9ppb7bFvWfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9f6de397474642f68b203a9017307831",
            "d6f876391afb4e319e70c05c9c4b82c6",
            "931fab634a0d471f91690170bc27d3e0",
            "7223c71f5ee84c4683b8cf662acc9ea5",
            "cafeac3373764987951fd62809899adc",
            "3e88dac2a9b643c9853ca99a882a2e73",
            "ce0ced0d52634a7c8e0727bd3e04bb64",
            "ae7a7838ccad4db2a3ca9ab6b19743f7",
            "7fcef851b2fa42299056721101e28aa1",
            "58b4827fb6ef4246943cf5ed46a7efe4",
            "0a8a6a9e4cba4e16aee80f43b993e61d"
          ]
        },
        "outputId": "d4848b33-ce3b-4fdc-d0d3-cc7c82e3f6c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4349 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f6de397474642f68b203a9017307831"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "0: 384x640 17 persons, 4 cars, 1 motorcycle, 1 bus, 1 truck, 2 traffic lights, 1 backpack, 33.3ms\n",
            "Speed: 0.5ms preprocess, 33.3ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 5 cars, 1 truck, 1 traffic light, 1 backpack, 1 handbag, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 4 cars, 1 motorcycle, 1 bus, 2 trucks, 3 traffic lights, 1 backpack, 1 handbag, 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 5 cars, 1 bus, 1 truck, 3 traffic lights, 1 backpack, 1 handbag, 33.5ms\n",
            "Speed: 0.6ms preprocess, 33.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 5 cars, 1 bus, 1 truck, 3 traffic lights, 1 handbag, 33.7ms\n",
            "Speed: 0.6ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 2 handbags, 1 cell phone, 33.2ms\n",
            "Speed: 0.5ms preprocess, 33.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 1 cell phone, 33.5ms\n",
            "Speed: 0.6ms preprocess, 33.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 1 handbag, 1 cell phone, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 1 cell phone, 33.0ms\n",
            "Speed: 0.7ms preprocess, 33.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 cars, 1 cell phone, 35.8ms\n",
            "Speed: 0.5ms preprocess, 35.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 1 backpack, 1 cell phone, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 cars, 1 backpack, 1 cell phone, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 persons, 3 cars, 1 backpack, 1 cell phone, 32.4ms\n",
            "Speed: 0.5ms preprocess, 32.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 4 cars, 1 backpack, 1 cell phone, 37.0ms\n",
            "Speed: 0.5ms preprocess, 37.0ms inference, 9.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 4 cars, 1 backpack, 35.1ms\n",
            "Speed: 0.8ms preprocess, 35.1ms inference, 11.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 backpack, 1 cell phone, 45.0ms\n",
            "Speed: 0.5ms preprocess, 45.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 4 cars, 1 backpack, 39.8ms\n",
            "Speed: 0.6ms preprocess, 39.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 backpack, 1 cell phone, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 backpack, 1 cell phone, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 2 backpacks, 36.7ms\n",
            "Speed: 2.5ms preprocess, 36.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 1 backpack, 1 cell phone, 37.6ms\n",
            "Speed: 0.5ms preprocess, 37.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 cars, 1 backpack, 1 handbag, 1 cell phone, 82.2ms\n",
            "Speed: 0.5ms preprocess, 82.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 4 cars, 1 backpack, 1 handbag, 1 cell phone, 53.3ms\n",
            "Speed: 0.6ms preprocess, 53.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 4 cars, 1 handbag, 1 cell phone, 47.4ms\n",
            "Speed: 0.5ms preprocess, 47.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 4 cars, 1 backpack, 2 handbags, 1 cell phone, 49.2ms\n",
            "Speed: 0.5ms preprocess, 49.2ms inference, 11.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 5 cars, 1 handbag, 1 cell phone, 75.5ms\n",
            "Speed: 0.6ms preprocess, 75.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 persons, 4 cars, 1 backpack, 2 handbags, 1 cell phone, 52.9ms\n",
            "Speed: 0.5ms preprocess, 52.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 cars, 1 backpack, 1 handbag, 1 cell phone, 46.1ms\n",
            "Speed: 0.5ms preprocess, 46.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 5 cars, 1 handbag, 1 cell phone, 66.3ms\n",
            "Speed: 10.6ms preprocess, 66.3ms inference, 7.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 4 cars, 2 handbags, 1 cell phone, 99.7ms\n",
            "Speed: 0.5ms preprocess, 99.7ms inference, 35.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 5 cars, 3 handbags, 1 cell phone, 90.6ms\n",
            "Speed: 0.5ms preprocess, 90.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 cars, 3 handbags, 1 cell phone, 88.7ms\n",
            "Speed: 0.5ms preprocess, 88.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 cars, 2 handbags, 65.9ms\n",
            "Speed: 1.8ms preprocess, 65.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 5 cars, 3 handbags, 62.7ms\n",
            "Speed: 0.5ms preprocess, 62.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 cars, 3 handbags, 1 cell phone, 64.5ms\n",
            "Speed: 12.6ms preprocess, 64.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 5 cars, 2 handbags, 1 cell phone, 63.1ms\n",
            "Speed: 0.5ms preprocess, 63.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 cars, 3 handbags, 1 cell phone, 89.7ms\n",
            "Speed: 17.6ms preprocess, 89.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 4 cars, 2 handbags, 1 cell phone, 62.8ms\n",
            "Speed: 2.6ms preprocess, 62.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 4 cars, 2 handbags, 63.1ms\n",
            "Speed: 0.5ms preprocess, 63.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 cars, 1 handbag, 64.5ms\n",
            "Speed: 0.5ms preprocess, 64.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 4 cars, 2 handbags, 1 cell phone, 57.8ms\n",
            "Speed: 0.5ms preprocess, 57.8ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 4 cars, 2 handbags, 50.3ms\n",
            "Speed: 0.5ms preprocess, 50.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 cars, 2 handbags, 1 cell phone, 50.6ms\n",
            "Speed: 0.5ms preprocess, 50.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 cars, 2 handbags, 50.0ms\n",
            "Speed: 0.5ms preprocess, 50.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 cars, 2 handbags, 51.3ms\n",
            "Speed: 0.5ms preprocess, 51.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 cars, 3 handbags, 43.1ms\n",
            "Speed: 0.6ms preprocess, 43.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 cars, 2 handbags, 43.0ms\n",
            "Speed: 3.6ms preprocess, 43.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 cars, 2 handbags, 1 cell phone, 44.7ms\n",
            "Speed: 0.5ms preprocess, 44.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 cars, 2 handbags, 47.0ms\n",
            "Speed: 0.5ms preprocess, 47.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 cars, 2 handbags, 43.1ms\n",
            "Speed: 0.5ms preprocess, 43.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 cars, 2 handbags, 43.0ms\n",
            "Speed: 0.6ms preprocess, 43.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 cars, 2 handbags, 45.7ms\n",
            "Speed: 0.5ms preprocess, 45.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 cars, 2 handbags, 42.3ms\n",
            "Speed: 0.5ms preprocess, 42.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 cars, 3 handbags, 42.1ms\n",
            "Speed: 0.5ms preprocess, 42.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 2 handbags, 39.9ms\n",
            "Speed: 0.5ms preprocess, 39.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 2 handbags, 40.0ms\n",
            "Speed: 0.5ms preprocess, 40.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 4 handbags, 41.0ms\n",
            "Speed: 0.5ms preprocess, 41.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 2 handbags, 42.3ms\n",
            "Speed: 0.5ms preprocess, 42.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 2 handbags, 44.9ms\n",
            "Speed: 0.6ms preprocess, 44.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 2 handbags, 43.4ms\n",
            "Speed: 0.5ms preprocess, 43.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 2 handbags, 56.8ms\n",
            "Speed: 0.5ms preprocess, 56.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 cars, 2 handbags, 40.1ms\n",
            "Speed: 4.2ms preprocess, 40.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 3 handbags, 39.9ms\n",
            "Speed: 0.5ms preprocess, 39.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 cars, 2 handbags, 40.0ms\n",
            "Speed: 1.0ms preprocess, 40.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 4 handbags, 40.0ms\n",
            "Speed: 0.6ms preprocess, 40.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 2 handbags, 1 suitcase, 42.3ms\n",
            "Speed: 0.5ms preprocess, 42.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 2 handbags, 1 suitcase, 43.1ms\n",
            "Speed: 0.5ms preprocess, 43.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 2 handbags, 45.1ms\n",
            "Speed: 0.5ms preprocess, 45.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 2 handbags, 43.8ms\n",
            "Speed: 1.4ms preprocess, 43.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 handbag, 1 suitcase, 41.1ms\n",
            "Speed: 0.5ms preprocess, 41.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 cars, 1 handbag, 1 suitcase, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 cars, 2 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 handbag, 1 suitcase, 39.5ms\n",
            "Speed: 1.1ms preprocess, 39.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 1 suitcase, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 1 handbag, 1 suitcase, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 backpack, 1 handbag, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 handbag, 1 suitcase, 39.8ms\n",
            "Speed: 0.5ms preprocess, 39.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 handbag, 1 suitcase, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 handbag, 1 suitcase, 45.7ms\n",
            "Speed: 0.5ms preprocess, 45.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 handbag, 1 suitcase, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 4 handbags, 1 suitcase, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 4 handbags, 1 suitcase, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 4 handbags, 1 suitcase, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 2 handbags, 1 suitcase, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 handbag, 1 suitcase, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 2 handbags, 1 suitcase, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 handbag, 1 suitcase, 39.6ms\n",
            "Speed: 0.5ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 2 handbags, 1 suitcase, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 handbag, 1 suitcase, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 1 handbag, 1 suitcase, 40.2ms\n",
            "Speed: 0.5ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 handbag, 1 suitcase, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 2 handbags, 1 suitcase, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 handbag, 2 suitcases, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 handbag, 1 suitcase, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 suitcase, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 handbag, 39.0ms\n",
            "Speed: 0.6ms preprocess, 39.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 backpack, 1 handbag, 2 suitcases, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 handbag, 39.0ms\n",
            "Speed: 0.7ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 handbag, 39.1ms\n",
            "Speed: 0.6ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 handbag, 38.6ms\n",
            "Speed: 0.5ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 38.1ms\n",
            "Speed: 0.9ms preprocess, 38.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 handbag, 1 suitcase, 34.8ms\n",
            "Speed: 0.5ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 36.1ms\n",
            "Speed: 0.4ms preprocess, 36.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 34.5ms\n",
            "Speed: 0.6ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 34.9ms\n",
            "Speed: 0.5ms preprocess, 34.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 handbag, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 cars, 1 handbag, 37.5ms\n",
            "Speed: 0.6ms preprocess, 37.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 35.1ms\n",
            "Speed: 0.6ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 cars, 1 handbag, 36.1ms\n",
            "Speed: 0.5ms preprocess, 36.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 34.6ms\n",
            "Speed: 0.5ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 cars, 2 handbags, 34.9ms\n",
            "Speed: 0.5ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 1 handbag, 35.1ms\n",
            "Speed: 0.6ms preprocess, 35.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 34.9ms\n",
            "Speed: 0.5ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 34.5ms\n",
            "Speed: 0.5ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 handbag, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 cars, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 handbag, 33.5ms\n",
            "Speed: 0.6ms preprocess, 33.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 1 handbag, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 cars, 1 traffic light, 1 handbag, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 handbag, 33.2ms\n",
            "Speed: 0.5ms preprocess, 33.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 3 cars, 1 handbag, 33.3ms\n",
            "Speed: 0.5ms preprocess, 33.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 33.6ms\n",
            "Speed: 0.5ms preprocess, 33.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 handbag, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 handbag, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 cars, 33.6ms\n",
            "Speed: 0.5ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 handbag, 33.2ms\n",
            "Speed: 0.5ms preprocess, 33.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 32.7ms\n",
            "Speed: 0.4ms preprocess, 32.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 backpack, 1 handbag, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 backpack, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 1 backpack, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 1 backpack, 1 handbag, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 backpack, 1 handbag, 35.2ms\n",
            "Speed: 0.5ms preprocess, 35.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 backpack, 1 handbag, 41.3ms\n",
            "Speed: 0.5ms preprocess, 41.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 backpack, 1 handbag, 35.4ms\n",
            "Speed: 0.5ms preprocess, 35.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 1 backpack, 1 handbag, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 backpack, 1 handbag, 35.9ms\n",
            "Speed: 0.5ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 backpack, 1 handbag, 36.3ms\n",
            "Speed: 0.5ms preprocess, 36.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 1 backpack, 1 handbag, 35.4ms\n",
            "Speed: 0.5ms preprocess, 35.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 backpack, 1 handbag, 37.3ms\n",
            "Speed: 0.4ms preprocess, 37.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 backpack, 1 handbag, 35.0ms\n",
            "Speed: 0.5ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 backpack, 1 handbag, 37.6ms\n",
            "Speed: 0.5ms preprocess, 37.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 cars, 2 backpacks, 35.3ms\n",
            "Speed: 0.5ms preprocess, 35.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 cars, 2 backpacks, 38.1ms\n",
            "Speed: 0.5ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 1 backpack, 1 handbag, 34.9ms\n",
            "Speed: 0.5ms preprocess, 34.9ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 backpack, 1 handbag, 34.5ms\n",
            "Speed: 0.6ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 1 backpack, 1 handbag, 34.5ms\n",
            "Speed: 0.6ms preprocess, 34.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 backpack, 34.5ms\n",
            "Speed: 0.5ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 backpack, 35.0ms\n",
            "Speed: 1.0ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 cars, 1 backpack, 34.6ms\n",
            "Speed: 0.8ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 backpack, 34.9ms\n",
            "Speed: 0.6ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 backpack, 1 handbag, 34.6ms\n",
            "Speed: 0.5ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 31.4ms\n",
            "Speed: 0.5ms preprocess, 31.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 handbag, 36.7ms\n",
            "Speed: 0.5ms preprocess, 36.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 cars, 1 handbag, 31.3ms\n",
            "Speed: 0.5ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 handbag, 31.7ms\n",
            "Speed: 0.5ms preprocess, 31.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 handbag, 32.1ms\n",
            "Speed: 0.5ms preprocess, 32.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 backpack, 1 handbag, 31.3ms\n",
            "Speed: 0.5ms preprocess, 31.3ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 backpack, 1 handbag, 31.5ms\n",
            "Speed: 0.5ms preprocess, 31.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 1 backpack, 1 handbag, 32.6ms\n",
            "Speed: 7.5ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 backpack, 1 handbag, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 backpack, 33.3ms\n",
            "Speed: 0.5ms preprocess, 33.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 1 backpack, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 backpack, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 1 backpack, 1 handbag, 34.2ms\n",
            "Speed: 0.5ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 cars, 1 backpack, 33.0ms\n",
            "Speed: 0.6ms preprocess, 33.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 4 cars, 1 backpack, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 cars, 1 backpack, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 1 backpack, 1 handbag, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 1 backpack, 33.4ms\n",
            "Speed: 0.5ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 cars, 2 backpacks, 1 handbag, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 cars, 2 backpacks, 1 handbag, 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 cars, 2 backpacks, 1 handbag, 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 1 backpack, 1 handbag, 37.4ms\n",
            "Speed: 0.6ms preprocess, 37.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 3 cars, 1 backpack, 34.3ms\n",
            "Speed: 3.7ms preprocess, 34.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 1 backpack, 1 handbag, 36.8ms\n",
            "Speed: 0.5ms preprocess, 36.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 1 backpack, 32.6ms\n",
            "Speed: 0.6ms preprocess, 32.6ms inference, 7.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 cars, 1 backpack, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 1 backpack, 1 handbag, 38.4ms\n",
            "Speed: 0.5ms preprocess, 38.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 1 backpack, 1 handbag, 41.0ms\n",
            "Speed: 0.5ms preprocess, 41.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 cars, 1 backpack, 39.8ms\n",
            "Speed: 0.5ms preprocess, 39.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 2 backpacks, 1 handbag, 38.6ms\n",
            "Speed: 0.5ms preprocess, 38.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 1 backpack, 1 handbag, 39.7ms\n",
            "Speed: 0.5ms preprocess, 39.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 cars, 1 backpack, 1 handbag, 40.6ms\n",
            "Speed: 0.5ms preprocess, 40.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 cars, 1 backpack, 2 handbags, 41.7ms\n",
            "Speed: 0.5ms preprocess, 41.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 cars, 1 backpack, 1 handbag, 40.3ms\n",
            "Speed: 0.5ms preprocess, 40.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 cars, 1 backpack, 2 handbags, 39.5ms\n",
            "Speed: 0.4ms preprocess, 39.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 cars, 1 backpack, 2 handbags, 40.3ms\n",
            "Speed: 0.5ms preprocess, 40.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 cars, 1 backpack, 1 handbag, 38.7ms\n",
            "Speed: 0.5ms preprocess, 38.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 8 handbags, 1 bottle, 40.0ms\n",
            "Speed: 0.6ms preprocess, 40.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 7 handbags, 1 bottle, 42.3ms\n",
            "Speed: 1.4ms preprocess, 42.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 6 handbags, 1 bottle, 40.0ms\n",
            "Speed: 0.5ms preprocess, 40.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 5 handbags, 1 bottle, 41.9ms\n",
            "Speed: 6.1ms preprocess, 41.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 6 handbags, 1 bottle, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 4 handbags, 1 bottle, 40.2ms\n",
            "Speed: 0.5ms preprocess, 40.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 handbags, 1 bottle, 41.2ms\n",
            "Speed: 0.7ms preprocess, 41.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 4 handbags, 1 bottle, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 handbags, 1 bottle, 1 cup, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 4 handbags, 1 bottle, 1 cup, 41.2ms\n",
            "Speed: 0.6ms preprocess, 41.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 4 handbags, 1 cup, 42.0ms\n",
            "Speed: 0.5ms preprocess, 42.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 4 handbags, 1 bottle, 1 cup, 39.7ms\n",
            "Speed: 0.5ms preprocess, 39.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 handbags, 1 tie, 42.6ms\n",
            "Speed: 0.5ms preprocess, 42.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 4 handbags, 1 tie, 1 cup, 42.3ms\n",
            "Speed: 0.5ms preprocess, 42.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 backpacks, 5 handbags, 1 tie, 1 wine glass, 39.6ms\n",
            "Speed: 0.5ms preprocess, 39.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 3 handbags, 1 tie, 39.4ms\n",
            "Speed: 1.6ms preprocess, 39.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 5 handbags, 1 tie, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 3 backpacks, 3 handbags, 1 tie, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 backpacks, 4 handbags, 1 tie, 42.1ms\n",
            "Speed: 0.5ms preprocess, 42.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 backpacks, 5 handbags, 1 tie, 2 cups, 40.7ms\n",
            "Speed: 0.6ms preprocess, 40.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 backpacks, 5 handbags, 1 tie, 1 cup, 40.2ms\n",
            "Speed: 0.5ms preprocess, 40.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 4 backpacks, 4 handbags, 1 tie, 1 cup, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 3 backpacks, 3 handbags, 1 tie, 1 cell phone, 40.8ms\n",
            "Speed: 0.6ms preprocess, 40.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 backpacks, 3 handbags, 1 tie, 1 cup, 39.8ms\n",
            "Speed: 0.5ms preprocess, 39.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 backpacks, 3 handbags, 1 tie, 1 wine glass, 1 cup, 39.6ms\n",
            "Speed: 1.6ms preprocess, 39.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 backpacks, 3 handbags, 1 tie, 1 cell phone, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 backpacks, 3 handbags, 2 ties, 39.1ms\n",
            "Speed: 0.6ms preprocess, 39.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 2 handbags, 2 ties, 1 cup, 39.6ms\n",
            "Speed: 0.5ms preprocess, 39.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 2 handbags, 2 ties, 1 bottle, 39.0ms\n",
            "Speed: 0.6ms preprocess, 39.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 2 handbags, 1 tie, 1 cup, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 2 handbags, 1 tie, 1 cup, 39.8ms\n",
            "Speed: 0.5ms preprocess, 39.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 3 handbags, 1 tie, 2 cups, 39.3ms\n",
            "Speed: 0.6ms preprocess, 39.3ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 backpacks, 4 handbags, 1 cup, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 3 handbags, 1 bottle, 1 cup, 41.8ms\n",
            "Speed: 0.5ms preprocess, 41.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 4 handbags, 1 bottle, 1 cup, 47.2ms\n",
            "Speed: 0.6ms preprocess, 47.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 5 handbags, 1 bottle, 1 cup, 41.6ms\n",
            "Speed: 0.9ms preprocess, 41.6ms inference, 7.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 5 handbags, 1 cup, 45.5ms\n",
            "Speed: 0.5ms preprocess, 45.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 5 handbags, 1 cup, 1 cell phone, 40.6ms\n",
            "Speed: 0.5ms preprocess, 40.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 6 handbags, 1 cell phone, 40.6ms\n",
            "Speed: 0.5ms preprocess, 40.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 6 handbags, 41.9ms\n",
            "Speed: 0.6ms preprocess, 41.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 handbags, 42.0ms\n",
            "Speed: 0.5ms preprocess, 42.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 5 handbags, 1 tie, 40.5ms\n",
            "Speed: 0.5ms preprocess, 40.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 5 handbags, 2 ties, 1 bottle, 39.8ms\n",
            "Speed: 0.5ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 5 handbags, 2 ties, 38.1ms\n",
            "Speed: 0.6ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 5 handbags, 1 tie, 35.7ms\n",
            "Speed: 0.5ms preprocess, 35.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 5 handbags, 1 tie, 35.5ms\n",
            "Speed: 0.5ms preprocess, 35.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 handbags, 1 tie, 1 cup, 1 cell phone, 35.7ms\n",
            "Speed: 0.5ms preprocess, 35.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 4 handbags, 1 tie, 1 cup, 35.3ms\n",
            "Speed: 0.5ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 6 handbags, 1 cup, 35.7ms\n",
            "Speed: 0.5ms preprocess, 35.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 5 handbags, 1 tie, 2 cups, 35.5ms\n",
            "Speed: 0.5ms preprocess, 35.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 5 handbags, 2 cups, 36.2ms\n",
            "Speed: 0.5ms preprocess, 36.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 3 handbags, 2 cups, 35.4ms\n",
            "Speed: 0.5ms preprocess, 35.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 3 handbags, 2 cups, 34.7ms\n",
            "Speed: 0.5ms preprocess, 34.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 2 handbags, 1 tie, 1 cup, 35.5ms\n",
            "Speed: 0.5ms preprocess, 35.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 2 handbags, 36.1ms\n",
            "Speed: 1.1ms preprocess, 36.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 2 handbags, 1 tie, 1 bottle, 34.6ms\n",
            "Speed: 0.5ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 2 handbags, 1 tie, 1 bottle, 35.0ms\n",
            "Speed: 0.6ms preprocess, 35.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 1 backpack, 2 handbags, 33.7ms\n",
            "Speed: 3.3ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 2 handbags, 33.9ms\n",
            "Speed: 0.6ms preprocess, 33.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 1 handbag, 1 tie, 2 cups, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 1 handbag, 1 tie, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 1 handbag, 2 ties, 1 cup, 37.2ms\n",
            "Speed: 0.5ms preprocess, 37.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 1 handbag, 1 tie, 1 cup, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 1 handbag, 1 tie, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 backpacks, 1 handbag, 1 tie, 2 cups, 34.4ms\n",
            "Speed: 0.6ms preprocess, 34.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 backpacks, 1 handbag, 2 ties, 1 cell phone, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 1 handbag, 1 tie, 1 bottle, 1 cell phone, 35.0ms\n",
            "Speed: 0.5ms preprocess, 35.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 1 handbag, 34.6ms\n",
            "Speed: 0.5ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 2 handbags, 1 cup, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 1 handbag, 2 wine glasss, 34.7ms\n",
            "Speed: 0.5ms preprocess, 34.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 2 handbags, 1 bottle, 2 wine glasss, 33.2ms\n",
            "Speed: 0.5ms preprocess, 33.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 3 handbags, 1 bottle, 1 wine glass, 32.4ms\n",
            "Speed: 0.7ms preprocess, 32.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 1 handbag, 1 bottle, 1 wine glass, 32.3ms\n",
            "Speed: 1.0ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 2 handbags, 2 bottles, 2 cups, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 1 bottle, 2 cups, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 3 handbags, 1 bottle, 2 cups, 35.2ms\n",
            "Speed: 0.5ms preprocess, 35.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 2 bottles, 1 cup, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 3 handbags, 2 bottles, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 backpack, 2 handbags, 1 bottle, 1 cup, 32.6ms\n",
            "Speed: 0.6ms preprocess, 32.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 1 bottle, 2 cups, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 3 handbags, 1 bottle, 2 cups, 33.3ms\n",
            "Speed: 0.5ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 2 handbags, 2 cups, 37.0ms\n",
            "Speed: 0.4ms preprocess, 37.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 2 handbags, 1 bottle, 2 cups, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 3 handbags, 1 bottle, 2 cups, 34.6ms\n",
            "Speed: 0.7ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 handbags, 1 bottle, 3 cups, 34.2ms\n",
            "Speed: 0.6ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 3 handbags, 1 bottle, 2 cups, 37.3ms\n",
            "Speed: 0.5ms preprocess, 37.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 4 handbags, 2 cups, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 backpacks, 3 handbags, 34.5ms\n",
            "Speed: 0.5ms preprocess, 34.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 2 handbags, 1 wine glass, 34.2ms\n",
            "Speed: 0.8ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 1 umbrella, 2 handbags, 1 bottle, 1 cell phone, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 2 handbags, 1 bottle, 1 cup, 33.3ms\n",
            "Speed: 0.5ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 handbags, 1 bottle, 1 cup, 1 cell phone, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 handbags, 1 bottle, 1 cup, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 backpack, 1 handbag, 2 bottles, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 2 bottles, 1 cup, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 2 bottles, 1 cup, 33.2ms\n",
            "Speed: 0.6ms preprocess, 33.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bus, 1 truck, 2 traffic lights, 7 backpacks, 5 handbags, 2 suitcases, 33.5ms\n",
            "Speed: 1.0ms preprocess, 33.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 6 backpacks, 6 handbags, 2 suitcases, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bus, 1 truck, 2 traffic lights, 6 backpacks, 5 handbags, 33.4ms\n",
            "Speed: 0.5ms preprocess, 33.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 buss, 2 traffic lights, 4 backpacks, 5 handbags, 36.3ms\n",
            "Speed: 0.5ms preprocess, 36.3ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 buss, 2 traffic lights, 5 backpacks, 5 handbags, 33.3ms\n",
            "Speed: 0.8ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 3 buss, 2 traffic lights, 5 backpacks, 4 handbags, 1 potted plant, 34.9ms\n",
            "Speed: 0.5ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 buss, 2 traffic lights, 5 backpacks, 5 handbags, 32.7ms\n",
            "Speed: 0.8ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 buss, 3 traffic lights, 4 backpacks, 4 handbags, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bus, 3 traffic lights, 4 backpacks, 5 handbags, 33.7ms\n",
            "Speed: 0.8ms preprocess, 33.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 buss, 3 traffic lights, 4 backpacks, 4 handbags, 33.6ms\n",
            "Speed: 0.5ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 buss, 3 traffic lights, 4 backpacks, 5 handbags, 33.3ms\n",
            "Speed: 0.6ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 3 traffic lights, 3 backpacks, 6 handbags, 33.6ms\n",
            "Speed: 0.5ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bus, 2 traffic lights, 3 backpacks, 4 handbags, 1 potted plant, 33.5ms\n",
            "Speed: 0.5ms preprocess, 33.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 buss, 2 traffic lights, 3 backpacks, 5 handbags, 1 potted plant, 35.0ms\n",
            "Speed: 0.6ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 buss, 2 traffic lights, 3 backpacks, 7 handbags, 1 potted plant, 35.1ms\n",
            "Speed: 0.4ms preprocess, 35.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 buss, 1 truck, 3 traffic lights, 4 backpacks, 5 handbags, 1 potted plant, 35.6ms\n",
            "Speed: 0.5ms preprocess, 35.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 buss, 1 truck, 2 traffic lights, 3 backpacks, 5 handbags, 1 potted plant, 35.6ms\n",
            "Speed: 0.5ms preprocess, 35.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 buss, 1 truck, 2 traffic lights, 4 backpacks, 2 handbags, 1 potted plant, 36.1ms\n",
            "Speed: 0.5ms preprocess, 36.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 4 handbags, 1 potted plant, 36.1ms\n",
            "Speed: 0.6ms preprocess, 36.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 4 backpacks, 8 handbags, 1 potted plant, 35.9ms\n",
            "Speed: 0.5ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bus, 1 truck, 2 traffic lights, 4 backpacks, 3 handbags, 1 potted plant, 35.0ms\n",
            "Speed: 0.5ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bus, 2 traffic lights, 4 backpacks, 4 handbags, 1 potted plant, 36.0ms\n",
            "Speed: 0.4ms preprocess, 36.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 buss, 2 traffic lights, 4 backpacks, 5 handbags, 1 potted plant, 35.9ms\n",
            "Speed: 0.7ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 buss, 2 traffic lights, 5 backpacks, 6 handbags, 2 suitcases, 1 potted plant, 35.4ms\n",
            "Speed: 0.5ms preprocess, 35.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bus, 1 truck, 2 traffic lights, 6 backpacks, 8 handbags, 2 suitcases, 1 potted plant, 34.6ms\n",
            "Speed: 0.5ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 buss, 2 traffic lights, 6 backpacks, 7 handbags, 2 suitcases, 1 potted plant, 35.0ms\n",
            "Speed: 0.5ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 buss, 3 traffic lights, 4 backpacks, 8 handbags, 2 suitcases, 1 potted plant, 34.9ms\n",
            "Speed: 0.5ms preprocess, 34.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 buss, 2 traffic lights, 4 backpacks, 8 handbags, 2 suitcases, 1 potted plant, 34.6ms\n",
            "Speed: 0.5ms preprocess, 34.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 buss, 1 truck, 2 traffic lights, 5 backpacks, 5 handbags, 2 suitcases, 1 potted plant, 35.2ms\n",
            "Speed: 0.6ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bus, 1 truck, 2 traffic lights, 5 backpacks, 8 handbags, 2 suitcases, 1 potted plant, 35.0ms\n",
            "Speed: 0.5ms preprocess, 35.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 5 backpacks, 7 handbags, 2 suitcases, 1 potted plant, 35.1ms\n",
            "Speed: 0.5ms preprocess, 35.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 2 traffic lights, 5 backpacks, 5 handbags, 2 suitcases, 1 potted plant, 34.7ms\n",
            "Speed: 0.8ms preprocess, 34.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bus, 1 truck, 2 traffic lights, 5 backpacks, 5 handbags, 2 suitcases, 1 potted plant, 34.9ms\n",
            "Speed: 0.5ms preprocess, 34.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 5 backpacks, 5 handbags, 2 suitcases, 34.8ms\n",
            "Speed: 0.5ms preprocess, 34.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 buss, 1 truck, 2 traffic lights, 5 backpacks, 5 handbags, 2 suitcases, 34.6ms\n",
            "Speed: 0.6ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 buss, 1 truck, 3 traffic lights, 6 backpacks, 6 handbags, 2 suitcases, 38.0ms\n",
            "Speed: 0.6ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 buss, 1 truck, 3 traffic lights, 6 backpacks, 4 handbags, 2 suitcases, 34.8ms\n",
            "Speed: 0.5ms preprocess, 34.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 7 backpacks, 6 handbags, 2 suitcases, 34.9ms\n",
            "Speed: 0.5ms preprocess, 34.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 2 traffic lights, 7 backpacks, 6 handbags, 2 suitcases, 34.5ms\n",
            "Speed: 0.5ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bus, 1 truck, 2 traffic lights, 5 backpacks, 6 handbags, 2 suitcases, 35.3ms\n",
            "Speed: 1.4ms preprocess, 35.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 buss, 2 traffic lights, 5 backpacks, 7 handbags, 2 suitcases, 34.6ms\n",
            "Speed: 0.5ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 2 traffic lights, 5 backpacks, 5 handbags, 2 suitcases, 35.0ms\n",
            "Speed: 0.5ms preprocess, 35.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 2 traffic lights, 5 backpacks, 4 handbags, 2 suitcases, 34.6ms\n",
            "Speed: 0.6ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bus, 1 truck, 2 traffic lights, 6 backpacks, 4 handbags, 2 suitcases, 42.5ms\n",
            "Speed: 0.5ms preprocess, 42.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 5 handbags, 2 suitcases, 40.2ms\n",
            "Speed: 0.5ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bus, 1 truck, 2 traffic lights, 4 backpacks, 4 handbags, 1 suitcase, 36.8ms\n",
            "Speed: 0.5ms preprocess, 36.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 buss, 1 truck, 2 traffic lights, 5 backpacks, 4 handbags, 1 suitcase, 36.7ms\n",
            "Speed: 0.5ms preprocess, 36.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 2 traffic lights, 4 backpacks, 4 handbags, 3 suitcases, 37.3ms\n",
            "Speed: 0.5ms preprocess, 37.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 buss, 2 traffic lights, 4 backpacks, 5 handbags, 1 suitcase, 37.3ms\n",
            "Speed: 0.7ms preprocess, 37.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 buss, 2 traffic lights, 5 backpacks, 5 handbags, 1 suitcase, 37.6ms\n",
            "Speed: 0.6ms preprocess, 37.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bus, 1 truck, 3 traffic lights, 5 backpacks, 3 handbags, 2 suitcases, 37.7ms\n",
            "Speed: 0.5ms preprocess, 37.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bus, 1 truck, 3 traffic lights, 5 backpacks, 4 handbags, 3 suitcases, 1 cell phone, 39.0ms\n",
            "Speed: 0.6ms preprocess, 39.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bus, 1 traffic light, 5 backpacks, 3 handbags, 2 suitcases, 39.3ms\n",
            "Speed: 0.5ms preprocess, 39.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 traffic light, 5 backpacks, 4 handbags, 2 suitcases, 43.1ms\n",
            "Speed: 0.6ms preprocess, 43.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 4 backpacks, 4 handbags, 2 suitcases, 44.8ms\n",
            "Speed: 0.5ms preprocess, 44.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bus, 1 truck, 2 traffic lights, 4 backpacks, 4 handbags, 2 suitcases, 40.2ms\n",
            "Speed: 0.5ms preprocess, 40.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 3 traffic lights, 6 backpacks, 4 handbags, 2 suitcases, 39.1ms\n",
            "Speed: 0.7ms preprocess, 39.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 2 traffic lights, 7 backpacks, 3 handbags, 3 suitcases, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bus, 1 truck, 2 traffic lights, 4 backpacks, 2 handbags, 3 suitcases, 43.2ms\n",
            "Speed: 0.5ms preprocess, 43.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bus, 1 truck, 2 traffic lights, 5 backpacks, 3 handbags, 2 suitcases, 1 cell phone, 41.5ms\n",
            "Speed: 0.5ms preprocess, 41.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 buss, 1 truck, 2 traffic lights, 7 backpacks, 5 handbags, 1 suitcase, 1 cell phone, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 buss, 1 truck, 2 traffic lights, 5 backpacks, 4 handbags, 1 cell phone, 42.9ms\n",
            "Speed: 0.5ms preprocess, 42.9ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bus, 1 truck, 2 traffic lights, 1 bench, 6 backpacks, 3 handbags, 1 cell phone, 48.7ms\n",
            "Speed: 0.7ms preprocess, 48.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 2 traffic lights, 5 backpacks, 3 handbags, 46.6ms\n",
            "Speed: 0.5ms preprocess, 46.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bus, 1 truck, 2 traffic lights, 4 backpacks, 4 handbags, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 2 traffic lights, 4 backpacks, 4 handbags, 43.7ms\n",
            "Speed: 0.5ms preprocess, 43.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 4 handbags, 39.7ms\n",
            "Speed: 0.5ms preprocess, 39.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 5 handbags, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 2 traffic lights, 2 backpacks, 6 handbags, 42.8ms\n",
            "Speed: 0.5ms preprocess, 42.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bus, 2 traffic lights, 2 backpacks, 7 handbags, 1 cell phone, 39.0ms\n",
            "Speed: 0.7ms preprocess, 39.0ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 9 handbags, 1 cell phone, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 2 traffic lights, 1 backpack, 5 handbags, 1 cell phone, 40.9ms\n",
            "Speed: 0.5ms preprocess, 40.9ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 2 traffic lights, 1 backpack, 4 handbags, 1 remote, 1 cell phone, 40.6ms\n",
            "Speed: 0.5ms preprocess, 40.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 buss, 2 traffic lights, 2 backpacks, 4 handbags, 1 remote, 1 cell phone, 40.1ms\n",
            "Speed: 3.7ms preprocess, 40.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 buss, 2 traffic lights, 2 backpacks, 4 handbags, 1 cell phone, 39.0ms\n",
            "Speed: 0.4ms preprocess, 39.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 buss, 2 traffic lights, 1 backpack, 4 handbags, 1 cell phone, 41.7ms\n",
            "Speed: 0.5ms preprocess, 41.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bus, 1 truck, 2 traffic lights, 2 backpacks, 5 handbags, 45.7ms\n",
            "Speed: 0.5ms preprocess, 45.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 2 backpacks, 5 handbags, 1 cell phone, 40.9ms\n",
            "Speed: 0.5ms preprocess, 40.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bus, 1 truck, 2 traffic lights, 1 backpack, 3 handbags, 1 cell phone, 43.4ms\n",
            "Speed: 0.5ms preprocess, 43.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bus, 1 truck, 2 traffic lights, 1 backpack, 5 handbags, 1 suitcase, 1 cell phone, 41.8ms\n",
            "Speed: 0.5ms preprocess, 41.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bus, 1 truck, 2 traffic lights, 2 backpacks, 4 handbags, 41.6ms\n",
            "Speed: 0.5ms preprocess, 41.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 buss, 2 traffic lights, 2 backpacks, 4 handbags, 43.5ms\n",
            "Speed: 0.5ms preprocess, 43.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 buss, 1 truck, 2 traffic lights, 2 backpacks, 5 handbags, 42.5ms\n",
            "Speed: 0.5ms preprocess, 42.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 buss, 1 truck, 2 traffic lights, 2 backpacks, 4 handbags, 1 suitcase, 42.5ms\n",
            "Speed: 0.5ms preprocess, 42.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bus, 1 truck, 1 traffic light, 2 backpacks, 6 handbags, 1 suitcase, 46.1ms\n",
            "Speed: 0.5ms preprocess, 46.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bus, 1 truck, 2 traffic lights, 2 backpacks, 5 handbags, 1 suitcase, 56.7ms\n",
            "Speed: 0.5ms preprocess, 56.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bus, 1 truck, 2 traffic lights, 5 backpacks, 3 handbags, 1 suitcase, 43.7ms\n",
            "Speed: 0.5ms preprocess, 43.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 4 handbags, 1 suitcase, 1 wine glass, 1 cell phone, 46.6ms\n",
            "Speed: 0.5ms preprocess, 46.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bus, 1 truck, 3 traffic lights, 3 backpacks, 5 handbags, 1 suitcase, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 2 traffic lights, 2 backpacks, 4 handbags, 1 suitcase, 42.5ms\n",
            "Speed: 0.6ms preprocess, 42.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 3 traffic lights, 2 backpacks, 2 handbags, 1 suitcase, 41.7ms\n",
            "Speed: 0.5ms preprocess, 41.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bus, 2 traffic lights, 3 backpacks, 4 handbags, 3 suitcases, 1 potted plant, 41.7ms\n",
            "Speed: 0.5ms preprocess, 41.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 2 traffic lights, 3 backpacks, 6 handbags, 2 suitcases, 1 potted plant, 41.6ms\n",
            "Speed: 0.5ms preprocess, 41.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 2 traffic lights, 4 backpacks, 5 handbags, 1 suitcase, 1 potted plant, 41.8ms\n",
            "Speed: 0.6ms preprocess, 41.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 traffic light, 2 backpacks, 4 handbags, 1 suitcase, 41.7ms\n",
            "Speed: 0.5ms preprocess, 41.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 5 backpacks, 4 handbags, 1 suitcase, 41.3ms\n",
            "Speed: 0.5ms preprocess, 41.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bus, 1 truck, 1 traffic light, 5 backpacks, 3 handbags, 1 suitcase, 39.6ms\n",
            "Speed: 0.6ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bus, 1 traffic light, 3 backpacks, 4 handbags, 1 suitcase, 1 cell phone, 40.6ms\n",
            "Speed: 0.5ms preprocess, 40.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 1 traffic light, 4 backpacks, 3 handbags, 1 suitcase, 39.1ms\n",
            "Speed: 0.7ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bus, 1 truck, 1 traffic light, 4 backpacks, 4 handbags, 1 suitcase, 39.0ms\n",
            "Speed: 0.4ms preprocess, 39.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bus, 1 truck, 1 traffic light, 5 backpacks, 3 handbags, 1 suitcase, 39.2ms\n",
            "Speed: 0.5ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 4 handbags, 1 suitcase, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bus, 1 truck, 2 traffic lights, 4 backpacks, 3 handbags, 1 suitcase, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bus, 1 truck, 2 traffic lights, 4 backpacks, 3 handbags, 1 suitcase, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bus, 1 truck, 2 traffic lights, 4 backpacks, 3 handbags, 1 suitcase, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bus, 1 truck, 2 traffic lights, 4 backpacks, 4 handbags, 1 suitcase, 1 potted plant, 39.3ms\n",
            "Speed: 0.7ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bus, 1 truck, 2 traffic lights, 2 backpacks, 4 handbags, 1 suitcase, 1 potted plant, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 2 traffic lights, 4 backpacks, 4 handbags, 1 suitcase, 39.2ms\n",
            "Speed: 0.5ms preprocess, 39.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 4 handbags, 1 suitcase, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 5 backpacks, 4 handbags, 1 suitcase, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 3 handbags, 1 suitcase, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 3 traffic lights, 3 backpacks, 6 handbags, 1 suitcase, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 3 traffic lights, 3 backpacks, 5 handbags, 1 suitcase, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bus, 1 truck, 4 traffic lights, 3 backpacks, 5 handbags, 1 suitcase, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 4 handbags, 2 suitcases, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 3 handbags, 1 suitcase, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 4 handbags, 1 suitcase, 39.8ms\n",
            "Speed: 0.5ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 6 handbags, 1 suitcase, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 3 traffic lights, 4 backpacks, 6 handbags, 2 suitcases, 39.1ms\n",
            "Speed: 0.6ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 5 handbags, 1 suitcase, 40.2ms\n",
            "Speed: 0.6ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 5 handbags, 1 suitcase, 40.8ms\n",
            "Speed: 0.6ms preprocess, 40.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 7 handbags, 1 suitcase, 41.8ms\n",
            "Speed: 0.5ms preprocess, 41.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 5 handbags, 2 suitcases, 38.8ms\n",
            "Speed: 0.5ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 6 handbags, 2 suitcases, 40.4ms\n",
            "Speed: 0.6ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 7 handbags, 2 suitcases, 38.6ms\n",
            "Speed: 0.4ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 7 handbags, 1 suitcase, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 7 handbags, 1 suitcase, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 7 handbags, 1 suitcase, 41.0ms\n",
            "Speed: 0.5ms preprocess, 41.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 8 handbags, 1 suitcase, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 7 handbags, 1 suitcase, 40.9ms\n",
            "Speed: 0.5ms preprocess, 40.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 6 handbags, 1 suitcase, 37.9ms\n",
            "Speed: 0.5ms preprocess, 37.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 buss, 1 truck, 2 traffic lights, 2 backpacks, 6 handbags, 1 suitcase, 39.5ms\n",
            "Speed: 1.0ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 2 traffic lights, 2 backpacks, 7 handbags, 1 suitcase, 37.7ms\n",
            "Speed: 0.5ms preprocess, 37.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 2 traffic lights, 2 backpacks, 7 handbags, 1 suitcase, 39.3ms\n",
            "Speed: 0.5ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 8 handbags, 1 suitcase, 38.7ms\n",
            "Speed: 0.5ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 8 handbags, 2 suitcases, 36.5ms\n",
            "Speed: 0.5ms preprocess, 36.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 2 backpacks, 8 handbags, 1 suitcase, 37.0ms\n",
            "Speed: 0.5ms preprocess, 37.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bus, 1 truck, 3 traffic lights, 3 backpacks, 8 handbags, 1 suitcase, 36.5ms\n",
            "Speed: 0.5ms preprocess, 36.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 2 backpacks, 7 handbags, 1 suitcase, 35.3ms\n",
            "Speed: 0.7ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 7 handbags, 1 suitcase, 36.6ms\n",
            "Speed: 0.5ms preprocess, 36.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bus, 1 truck, 2 traffic lights, 3 backpacks, 7 handbags, 1 suitcase, 35.8ms\n",
            "Speed: 0.5ms preprocess, 35.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bus, 1 truck, 2 traffic lights, 1 backpack, 8 handbags, 1 suitcase, 1 skateboard, 36.6ms\n",
            "Speed: 0.5ms preprocess, 36.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bus, 1 truck, 2 traffic lights, 2 backpacks, 7 handbags, 1 suitcase, 37.8ms\n",
            "Speed: 0.4ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bus, 1 truck, 2 traffic lights, 5 handbags, 1 suitcase, 35.1ms\n",
            "Speed: 0.4ms preprocess, 35.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bus, 1 truck, 2 traffic lights, 5 handbags, 1 suitcase, 36.5ms\n",
            "Speed: 0.5ms preprocess, 36.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 backpack, 36.9ms\n",
            "Speed: 0.5ms preprocess, 36.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 backpack, 1 handbag, 36.7ms\n",
            "Speed: 0.6ms preprocess, 36.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 36.6ms\n",
            "Speed: 0.5ms preprocess, 36.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 36.6ms\n",
            "Speed: 0.4ms preprocess, 36.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 35.2ms\n",
            "Speed: 0.5ms preprocess, 35.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 backpack, 36.7ms\n",
            "Speed: 0.5ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 36.6ms\n",
            "Speed: 0.5ms preprocess, 36.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 backpack, 36.5ms\n",
            "Speed: 0.5ms preprocess, 36.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 3 buss, 1 truck, 1 backpack, 2 handbags, 35.3ms\n",
            "Speed: 0.5ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 backpack, 2 handbags, 36.8ms\n",
            "Speed: 0.5ms preprocess, 36.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 2 cars, 4 buss, 1 truck, 1 handbag, 36.6ms\n",
            "Speed: 0.5ms preprocess, 36.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 4 buss, 1 truck, 1 handbag, 36.8ms\n",
            "Speed: 0.7ms preprocess, 36.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 4 buss, 1 truck, 1 handbag, 36.5ms\n",
            "Speed: 0.5ms preprocess, 36.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 4 buss, 1 truck, 1 handbag, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 2 cars, 4 buss, 1 truck, 1 handbag, 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 5 buss, 1 truck, 3 handbags, 33.3ms\n",
            "Speed: 0.6ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 5 buss, 1 truck, 2 handbags, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 5 buss, 1 truck, 3 handbags, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 5 buss, 1 truck, 4 handbags, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 5 buss, 2 handbags, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 5 buss, 3 handbags, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 5 buss, 3 handbags, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 bicycle, 2 cars, 5 buss, 3 handbags, 33.0ms\n",
            "Speed: 0.6ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 4 buss, 3 handbags, 32.4ms\n",
            "Speed: 0.5ms preprocess, 32.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 bicycle, 2 cars, 4 buss, 4 handbags, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 4 buss, 3 handbags, 31.8ms\n",
            "Speed: 0.5ms preprocess, 31.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 bicycle, 2 cars, 4 buss, 2 handbags, 32.4ms\n",
            "Speed: 0.6ms preprocess, 32.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 3 buss, 2 handbags, 31.8ms\n",
            "Speed: 0.5ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 4 buss, 2 handbags, 32.6ms\n",
            "Speed: 0.4ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 2 cars, 4 buss, 1 truck, 2 handbags, 34.9ms\n",
            "Speed: 0.5ms preprocess, 34.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 4 buss, 1 truck, 3 handbags, 32.4ms\n",
            "Speed: 0.5ms preprocess, 32.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 2 handbags, 32.0ms\n",
            "Speed: 0.5ms preprocess, 32.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 4 handbags, 33.4ms\n",
            "Speed: 1.1ms preprocess, 33.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 3 handbags, 31.8ms\n",
            "Speed: 0.6ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 2 handbags, 32.2ms\n",
            "Speed: 0.5ms preprocess, 32.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 3 handbags, 32.1ms\n",
            "Speed: 0.5ms preprocess, 32.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 4 handbags, 32.2ms\n",
            "Speed: 0.4ms preprocess, 32.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 2 handbags, 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 2 cars, 4 buss, 1 truck, 3 handbags, 31.8ms\n",
            "Speed: 0.6ms preprocess, 31.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 2 cars, 3 buss, 1 truck, 4 handbags, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 2 handbags, 32.0ms\n",
            "Speed: 0.6ms preprocess, 32.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 2 handbags, 32.9ms\n",
            "Speed: 1.0ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 2 handbags, 31.8ms\n",
            "Speed: 0.5ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 2 handbags, 32.1ms\n",
            "Speed: 0.5ms preprocess, 32.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 3 handbags, 35.4ms\n",
            "Speed: 0.5ms preprocess, 35.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 2 handbags, 1 tie, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 3 handbags, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 3 handbags, 33.2ms\n",
            "Speed: 0.5ms preprocess, 33.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 2 handbags, 1 tie, 34.2ms\n",
            "Speed: 0.5ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 33.3ms\n",
            "Speed: 0.5ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 33.1ms\n",
            "Speed: 0.6ms preprocess, 33.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 37.0ms\n",
            "Speed: 0.5ms preprocess, 37.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 36.2ms\n",
            "Speed: 0.5ms preprocess, 36.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 33.6ms\n",
            "Speed: 0.5ms preprocess, 33.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 35.5ms\n",
            "Speed: 0.5ms preprocess, 35.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 41.2ms\n",
            "Speed: 0.4ms preprocess, 41.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 38.1ms\n",
            "Speed: 0.5ms preprocess, 38.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 43.6ms\n",
            "Speed: 0.5ms preprocess, 43.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 traffic light, 40.2ms\n",
            "Speed: 0.5ms preprocess, 40.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 38.6ms\n",
            "Speed: 0.5ms preprocess, 38.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 38.6ms\n",
            "Speed: 0.6ms preprocess, 38.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 46.0ms\n",
            "Speed: 0.6ms preprocess, 46.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 2 cars, 3 buss, 1 truck, 39.9ms\n",
            "Speed: 0.6ms preprocess, 39.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 42.5ms\n",
            "Speed: 0.6ms preprocess, 42.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 2 cars, 3 buss, 1 truck, 1 handbag, 41.8ms\n",
            "Speed: 0.5ms preprocess, 41.8ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 40.8ms\n",
            "Speed: 0.5ms preprocess, 40.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 42.9ms\n",
            "Speed: 0.5ms preprocess, 42.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 41.7ms\n",
            "Speed: 0.5ms preprocess, 41.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 44.6ms\n",
            "Speed: 0.5ms preprocess, 44.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 40.6ms\n",
            "Speed: 0.6ms preprocess, 40.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 3 buss, 1 truck, 2 handbags, 40.6ms\n",
            "Speed: 0.5ms preprocess, 40.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 3 buss, 1 truck, 3 handbags, 40.4ms\n",
            "Speed: 0.6ms preprocess, 40.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 3 buss, 1 truck, 2 handbags, 40.9ms\n",
            "Speed: 3.1ms preprocess, 40.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 bicycles, 2 cars, 3 buss, 1 truck, 2 handbags, 39.6ms\n",
            "Speed: 0.5ms preprocess, 39.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 bicycles, 2 cars, 3 buss, 1 truck, 3 handbags, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 3 handbags, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 3 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 3 handbags, 42.0ms\n",
            "Speed: 0.5ms preprocess, 42.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 bicycles, 2 cars, 3 buss, 1 truck, 3 handbags, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 bicycles, 2 cars, 3 buss, 1 truck, 3 handbags, 48.2ms\n",
            "Speed: 0.5ms preprocess, 48.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 bicycles, 2 cars, 3 buss, 1 truck, 3 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 1 traffic light, 3 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 1 handbag, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 2 handbags, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 2 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 2 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 1 handbag, 42.2ms\n",
            "Speed: 0.5ms preprocess, 42.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 1 traffic light, 41.0ms\n",
            "Speed: 0.5ms preprocess, 41.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 bicycles, 2 cars, 3 buss, 1 truck, 1 handbag, 41.6ms\n",
            "Speed: 0.5ms preprocess, 41.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 2 handbags, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 39.6ms\n",
            "Speed: 1.2ms preprocess, 39.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 41.4ms\n",
            "Speed: 0.5ms preprocess, 41.4ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 41.5ms\n",
            "Speed: 0.5ms preprocess, 41.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 1 handbag, 42.0ms\n",
            "Speed: 0.5ms preprocess, 42.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 1 handbag, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 1 handbag, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 cell phone, 40.2ms\n",
            "Speed: 0.5ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 cell phone, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 cell phone, 40.5ms\n",
            "Speed: 0.5ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 39.4ms\n",
            "Speed: 0.6ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 39.1ms\n",
            "Speed: 0.6ms preprocess, 39.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 40.6ms\n",
            "Speed: 0.5ms preprocess, 40.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 39.1ms\n",
            "Speed: 0.6ms preprocess, 39.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 39.0ms\n",
            "Speed: 0.6ms preprocess, 39.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 39.2ms\n",
            "Speed: 0.5ms preprocess, 39.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 1 handbag, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 39.7ms\n",
            "Speed: 0.5ms preprocess, 39.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 bicycles, 2 cars, 2 buss, 1 truck, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 40.2ms\n",
            "Speed: 0.5ms preprocess, 40.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 39.0ms\n",
            "Speed: 0.7ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 cars, 3 buss, 1 truck, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 bicycle, 2 cars, 2 buss, 1 truck, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 37.8ms\n",
            "Speed: 0.5ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 cars, 37.4ms\n",
            "Speed: 0.5ms preprocess, 37.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 37.5ms\n",
            "Speed: 0.5ms preprocess, 37.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 handbag, 32.8ms\n",
            "Speed: 1.2ms preprocess, 32.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 handbag, 31.1ms\n",
            "Speed: 0.5ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 32.1ms\n",
            "Speed: 0.5ms preprocess, 32.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 cars, 35.3ms\n",
            "Speed: 0.5ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 31.1ms\n",
            "Speed: 0.5ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 handbag, 32.2ms\n",
            "Speed: 0.5ms preprocess, 32.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 handbag, 32.3ms\n",
            "Speed: 0.6ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 backpack, 31.2ms\n",
            "Speed: 0.5ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 cars, 1 backpack, 32.1ms\n",
            "Speed: 0.5ms preprocess, 32.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 2 backpacks, 31.6ms\n",
            "Speed: 0.6ms preprocess, 31.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 backpack, 31.8ms\n",
            "Speed: 0.5ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 backpack, 37.3ms\n",
            "Speed: 0.5ms preprocess, 37.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 1 backpack, 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 backpack, 1 handbag, 32.1ms\n",
            "Speed: 0.5ms preprocess, 32.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 1 backpack, 31.2ms\n",
            "Speed: 0.5ms preprocess, 31.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 backpack, 32.1ms\n",
            "Speed: 0.5ms preprocess, 32.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 backpack, 31.1ms\n",
            "Speed: 0.5ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 31.8ms\n",
            "Speed: 0.4ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 34.7ms\n",
            "Speed: 4.1ms preprocess, 34.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 35.9ms\n",
            "Speed: 0.5ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 35.6ms\n",
            "Speed: 0.5ms preprocess, 35.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 33.6ms\n",
            "Speed: 0.6ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 33.0ms\n",
            "Speed: 0.6ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 1 backpack, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 1 backpack, 1 handbag, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 1 backpack, 1 handbag, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 1 backpack, 33.3ms\n",
            "Speed: 0.5ms preprocess, 33.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 cars, 33.4ms\n",
            "Speed: 0.5ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 1 backpack, 32.4ms\n",
            "Speed: 0.5ms preprocess, 32.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 backpack, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 36.6ms\n",
            "Speed: 0.5ms preprocess, 36.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 1 backpack, 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 1 backpack, 32.2ms\n",
            "Speed: 0.5ms preprocess, 32.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 backpack, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 1 backpack, 32.0ms\n",
            "Speed: 0.5ms preprocess, 32.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 suitcase, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 1 suitcase, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 1 backpack, 1 suitcase, 36.0ms\n",
            "Speed: 0.5ms preprocess, 36.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 1 backpack, 1 handbag, 1 suitcase, 31.8ms\n",
            "Speed: 0.6ms preprocess, 31.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 1 backpack, 1 suitcase, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 backpack, 1 handbag, 1 suitcase, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 1 backpack, 1 suitcase, 32.8ms\n",
            "Speed: 0.6ms preprocess, 32.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 1 backpack, 2 suitcases, 32.0ms\n",
            "Speed: 0.6ms preprocess, 32.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 1 backpack, 1 suitcase, 31.8ms\n",
            "Speed: 0.5ms preprocess, 31.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 1 backpack, 1 handbag, 1 suitcase, 31.8ms\n",
            "Speed: 0.5ms preprocess, 31.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 2 backpacks, 1 handbag, 2 suitcases, 32.4ms\n",
            "Speed: 0.6ms preprocess, 32.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 1 backpack, 1 handbag, 2 suitcases, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 1 suitcase, 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 2 handbags, 1 suitcase, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 2 handbags, 2 suitcases, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 4 handbags, 1 tie, 34.5ms\n",
            "Speed: 0.5ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 3 handbags, 2 ties, 34.5ms\n",
            "Speed: 0.5ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 3 handbags, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 1 umbrella, 3 handbags, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 traffic light, 3 handbags, 1 tie, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 1 bus, 1 traffic light, 5 handbags, 34.2ms\n",
            "Speed: 0.7ms preprocess, 34.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 1 bus, 5 handbags, 1 tie, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 7 handbags, 1 tie, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 6 handbags, 2 ties, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 5 handbags, 3 ties, 1 book, 33.9ms\n",
            "Speed: 0.5ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 1 bus, 3 handbags, 3 ties, 34.4ms\n",
            "Speed: 0.6ms preprocess, 34.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 1 bus, 1 truck, 4 handbags, 1 tie, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 3 handbags, 1 book, 34.3ms\n",
            "Speed: 0.6ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 4 handbags, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 3 handbags, 33.9ms\n",
            "Speed: 0.5ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 5 handbags, 1 tie, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 cars, 4 handbags, 1 tie, 34.3ms\n",
            "Speed: 0.6ms preprocess, 34.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 traffic light, 1 backpack, 5 handbags, 1 tie, 35.6ms\n",
            "Speed: 0.5ms preprocess, 35.6ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 cars, 1 traffic light, 1 backpack, 4 handbags, 33.7ms\n",
            "Speed: 4.8ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 2 backpacks, 5 handbags, 1 suitcase, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 bus, 1 traffic light, 1 backpack, 6 handbags, 36.2ms\n",
            "Speed: 0.5ms preprocess, 36.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 cars, 1 bus, 1 traffic light, 2 backpacks, 6 handbags, 1 suitcase, 33.7ms\n",
            "Speed: 3.1ms preprocess, 33.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 1 bus, 2 backpacks, 4 handbags, 34.0ms\n",
            "Speed: 0.6ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 cars, 2 backpacks, 4 handbags, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 truck, 1 traffic light, 2 backpacks, 3 handbags, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 2 backpacks, 6 handbags, 1 tie, 34.0ms\n",
            "Speed: 0.8ms preprocess, 34.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 3 backpacks, 5 handbags, 42.9ms\n",
            "Speed: 0.6ms preprocess, 42.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 cars, 2 backpacks, 3 handbags, 1 suitcase, 33.9ms\n",
            "Speed: 0.6ms preprocess, 33.9ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 2 backpacks, 2 handbags, 1 tie, 1 suitcase, 34.4ms\n",
            "Speed: 0.6ms preprocess, 34.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 1 truck, 1 backpack, 4 handbags, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 2 backpacks, 6 handbags, 1 tie, 34.5ms\n",
            "Speed: 0.6ms preprocess, 34.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 3 backpacks, 2 handbags, 1 suitcase, 1 book, 40.2ms\n",
            "Speed: 0.5ms preprocess, 40.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 2 backpacks, 5 handbags, 2 suitcases, 35.2ms\n",
            "Speed: 0.5ms preprocess, 35.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 cars, 1 truck, 3 backpacks, 4 handbags, 1 suitcase, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 cars, 1 truck, 2 backpacks, 6 handbags, 1 suitcase, 34.7ms\n",
            "Speed: 0.5ms preprocess, 34.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 cars, 1 truck, 2 backpacks, 6 handbags, 1 suitcase, 35.4ms\n",
            "Speed: 0.5ms preprocess, 35.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 3 cars, 1 truck, 1 traffic light, 2 backpacks, 3 handbags, 1 suitcase, 36.6ms\n",
            "Speed: 0.5ms preprocess, 36.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 cars, 3 backpacks, 5 handbags, 1 suitcase, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 cars, 3 backpacks, 2 handbags, 1 suitcase, 34.2ms\n",
            "Speed: 0.5ms preprocess, 34.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 cars, 3 backpacks, 2 handbags, 1 suitcase, 35.0ms\n",
            "Speed: 0.5ms preprocess, 35.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 truck, 3 backpacks, 6 handbags, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 cars, 1 truck, 4 backpacks, 5 handbags, 37.9ms\n",
            "Speed: 0.5ms preprocess, 37.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 5 cars, 5 backpacks, 6 handbags, 41.5ms\n",
            "Speed: 0.5ms preprocess, 41.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 5 cars, 1 truck, 6 backpacks, 3 handbags, 45.2ms\n",
            "Speed: 0.5ms preprocess, 45.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 cars, 1 truck, 5 backpacks, 5 handbags, 40.3ms\n",
            "Speed: 0.5ms preprocess, 40.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 cars, 1 truck, 5 backpacks, 3 handbags, 39.3ms\n",
            "Speed: 0.5ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 2 trucks, 5 backpacks, 4 handbags, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 2 trucks, 5 backpacks, 5 handbags, 41.3ms\n",
            "Speed: 2.7ms preprocess, 41.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 cars, 2 trucks, 5 backpacks, 4 handbags, 42.7ms\n",
            "Speed: 0.6ms preprocess, 42.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 cars, 1 truck, 5 backpacks, 6 handbags, 41.0ms\n",
            "Speed: 0.5ms preprocess, 41.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 cars, 1 truck, 4 backpacks, 5 handbags, 42.9ms\n",
            "Speed: 3.7ms preprocess, 42.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 4 backpacks, 3 handbags, 2 suitcases, 46.5ms\n",
            "Speed: 0.5ms preprocess, 46.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 4 backpacks, 2 handbags, 1 suitcase, 42.0ms\n",
            "Speed: 0.5ms preprocess, 42.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 4 backpacks, 4 handbags, 44.6ms\n",
            "Speed: 0.5ms preprocess, 44.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 3 backpacks, 4 handbags, 46.2ms\n",
            "Speed: 0.5ms preprocess, 46.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 3 backpacks, 5 handbags, 43.8ms\n",
            "Speed: 0.5ms preprocess, 43.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 5 backpacks, 4 handbags, 42.0ms\n",
            "Speed: 0.5ms preprocess, 42.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 bicycle, 2 cars, 6 backpacks, 3 handbags, 40.9ms\n",
            "Speed: 0.5ms preprocess, 40.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 5 backpacks, 4 handbags, 41.0ms\n",
            "Speed: 0.6ms preprocess, 41.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 cars, 5 backpacks, 5 handbags, 43.6ms\n",
            "Speed: 0.5ms preprocess, 43.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 cars, 5 backpacks, 4 handbags, 40.9ms\n",
            "Speed: 0.5ms preprocess, 40.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 5 backpacks, 3 handbags, 40.9ms\n",
            "Speed: 0.5ms preprocess, 40.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 4 cars, 4 backpacks, 3 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 2 handbags, 1 chair, 1 cell phone, 39.6ms\n",
            "Speed: 0.5ms preprocess, 39.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 4 handbags, 1 chair, 1 cell phone, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 3 handbags, 1 chair, 39.4ms\n",
            "Speed: 2.8ms preprocess, 39.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 3 handbags, 1 chair, 40.0ms\n",
            "Speed: 0.5ms preprocess, 40.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 2 handbags, 1 chair, 1 cell phone, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 2 handbags, 1 chair, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 4 handbags, 1 cup, 1 chair, 40.2ms\n",
            "Speed: 0.5ms preprocess, 40.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 5 handbags, 1 cup, 1 chair, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 4 handbags, 1 chair, 43.7ms\n",
            "Speed: 0.5ms preprocess, 43.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 6 handbags, 1 chair, 40.6ms\n",
            "Speed: 0.5ms preprocess, 40.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 6 handbags, 1 chair, 39.5ms\n",
            "Speed: 2.8ms preprocess, 39.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 3 handbags, 2 chairs, 44.5ms\n",
            "Speed: 0.5ms preprocess, 44.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 2 handbags, 1 tie, 39.6ms\n",
            "Speed: 0.5ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 1 handbag, 1 chair, 42.6ms\n",
            "Speed: 1.3ms preprocess, 42.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 1 handbag, 40.8ms\n",
            "Speed: 0.5ms preprocess, 40.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 1 backpack, 1 handbag, 40.3ms\n",
            "Speed: 0.5ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 2 handbags, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 bicycle, 3 handbags, 1 cell phone, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 bicycle, 2 handbags, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 handbags, 1 chair, 37.4ms\n",
            "Speed: 0.5ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 handbags, 1 chair, 36.8ms\n",
            "Speed: 0.4ms preprocess, 36.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 1 chair, 36.0ms\n",
            "Speed: 0.5ms preprocess, 36.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 3 handbags, 38.6ms\n",
            "Speed: 0.4ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 2 handbags, 34.6ms\n",
            "Speed: 0.5ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 3 handbags, 35.7ms\n",
            "Speed: 0.5ms preprocess, 35.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 2 handbags, 35.5ms\n",
            "Speed: 0.6ms preprocess, 35.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 3 handbags, 1 tie, 36.6ms\n",
            "Speed: 3.6ms preprocess, 36.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 3 handbags, 35.6ms\n",
            "Speed: 0.5ms preprocess, 35.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 3 handbags, 1 chair, 41.2ms\n",
            "Speed: 0.5ms preprocess, 41.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 1 backpack, 4 handbags, 1 chair, 35.4ms\n",
            "Speed: 0.5ms preprocess, 35.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 handbags, 1 chair, 35.3ms\n",
            "Speed: 0.5ms preprocess, 35.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 handbags, 1 chair, 35.4ms\n",
            "Speed: 0.5ms preprocess, 35.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 2 handbags, 1 chair, 34.6ms\n",
            "Speed: 0.5ms preprocess, 34.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 2 handbags, 1 chair, 32.3ms\n",
            "Speed: 0.4ms preprocess, 32.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 backpacks, 33.1ms\n",
            "Speed: 2.7ms preprocess, 33.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 persons, 2 backpacks, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 32.2ms\n",
            "Speed: 0.5ms preprocess, 32.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 handbag, 1 tie, 2 chairs, 32.1ms\n",
            "Speed: 0.5ms preprocess, 32.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 handbag, 1 chair, 32.8ms\n",
            "Speed: 0.6ms preprocess, 32.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 2 ties, 1 chair, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 handbags, 1 chair, 32.8ms\n",
            "Speed: 0.6ms preprocess, 32.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 handbags, 1 chair, 41.5ms\n",
            "Speed: 0.5ms preprocess, 41.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 handbags, 1 tie, 1 chair, 33.5ms\n",
            "Speed: 0.5ms preprocess, 33.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 4 handbags, 1 tie, 1 chair, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 handbags, 1 chair, 34.5ms\n",
            "Speed: 0.5ms preprocess, 34.5ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 5 handbags, 1 chair, 34.1ms\n",
            "Speed: 0.6ms preprocess, 34.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 handbags, 1 cell phone, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 handbags, 1 chair, 1 cell phone, 33.6ms\n",
            "Speed: 0.5ms preprocess, 33.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 handbags, 1 chair, 1 cell phone, 33.9ms\n",
            "Speed: 0.5ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 handbags, 1 chair, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 backpacks, 2 suitcases, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 handbag, 4 suitcases, 33.5ms\n",
            "Speed: 0.5ms preprocess, 33.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 backpacks, 2 handbags, 3 suitcases, 32.4ms\n",
            "Speed: 0.5ms preprocess, 32.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 backpacks, 1 handbag, 3 suitcases, 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 backpack, 2 handbags, 2 suitcases, 32.0ms\n",
            "Speed: 0.4ms preprocess, 32.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 backpacks, 2 handbags, 2 suitcases, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 3 backpacks, 2 handbags, 3 suitcases, 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 backpacks, 2 handbags, 2 suitcases, 35.3ms\n",
            "Speed: 0.5ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 1 backpack, 3 handbags, 2 suitcases, 31.5ms\n",
            "Speed: 0.5ms preprocess, 31.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 backpacks, 2 handbags, 2 suitcases, 30.6ms\n",
            "Speed: 0.5ms preprocess, 30.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 2 backpacks, 3 handbags, 3 suitcases, 30.6ms\n",
            "Speed: 0.4ms preprocess, 30.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 2 backpacks, 4 handbags, 1 suitcase, 31.1ms\n",
            "Speed: 0.6ms preprocess, 31.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 bicycle, 1 car, 2 backpacks, 2 handbags, 1 suitcase, 1 cell phone, 31.3ms\n",
            "Speed: 0.5ms preprocess, 31.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 bicycle, 1 car, 2 backpacks, 3 handbags, 1 suitcase, 30.6ms\n",
            "Speed: 0.5ms preprocess, 30.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 3 backpacks, 1 handbag, 1 suitcase, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 3 backpacks, 2 handbags, 1 suitcase, 1 bottle, 33.2ms\n",
            "Speed: 0.7ms preprocess, 33.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 2 backpacks, 4 handbags, 1 suitcase, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 2 backpacks, 2 handbags, 1 suitcase, 35.3ms\n",
            "Speed: 0.6ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 2 backpacks, 4 handbags, 2 suitcases, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 2 backpacks, 4 handbags, 1 suitcase, 1 chair, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 2 backpacks, 3 handbags, 1 suitcase, 1 chair, 33.9ms\n",
            "Speed: 0.5ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 2 backpacks, 2 handbags, 1 suitcase, 1 chair, 1 book, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 3 backpacks, 2 handbags, 2 suitcases, 1 chair, 1 cell phone, 34.2ms\n",
            "Speed: 0.5ms preprocess, 34.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 2 backpacks, 2 handbags, 1 suitcase, 1 chair, 2 cell phones, 33.6ms\n",
            "Speed: 0.5ms preprocess, 33.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 4 handbags, 2 suitcases, 1 cell phone, 33.4ms\n",
            "Speed: 0.5ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 backpacks, 4 handbags, 1 suitcase, 1 chair, 33.9ms\n",
            "Speed: 1.1ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 backpacks, 4 handbags, 2 suitcases, 1 chair, 1 cell phone, 33.4ms\n",
            "Speed: 0.6ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 4 handbags, 2 suitcases, 1 chair, 1 cell phone, 35.4ms\n",
            "Speed: 0.5ms preprocess, 35.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 backpacks, 2 handbags, 2 suitcases, 1 cell phone, 35.4ms\n",
            "Speed: 1.8ms preprocess, 35.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 bicycle, 2 backpacks, 5 handbags, 3 suitcases, 1 cell phone, 33.6ms\n",
            "Speed: 0.6ms preprocess, 33.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 3 handbags, 3 suitcases, 1 chair, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 3 handbags, 3 suitcases, 2 cell phones, 34.2ms\n",
            "Speed: 0.5ms preprocess, 34.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 bicycle, 2 backpacks, 8 handbags, 3 suitcases, 31.8ms\n",
            "Speed: 0.5ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 bicycle, 2 backpacks, 6 handbags, 3 suitcases, 1 cell phone, 31.0ms\n",
            "Speed: 0.6ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 bicycle, 2 backpacks, 6 handbags, 3 suitcases, 1 cell phone, 31.1ms\n",
            "Speed: 0.5ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 backpacks, 6 handbags, 3 suitcases, 30.8ms\n",
            "Speed: 0.5ms preprocess, 30.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 bicycle, 3 backpacks, 5 handbags, 3 suitcases, 31.8ms\n",
            "Speed: 0.5ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 backpacks, 7 handbags, 3 suitcases, 31.7ms\n",
            "Speed: 0.5ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 backpacks, 5 handbags, 3 suitcases, 32.1ms\n",
            "Speed: 0.5ms preprocess, 32.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 backpacks, 7 handbags, 3 suitcases, 32.2ms\n",
            "Speed: 0.5ms preprocess, 32.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 3 backpacks, 5 handbags, 3 suitcases, 31.8ms\n",
            "Speed: 0.5ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 backpacks, 5 handbags, 3 suitcases, 31.6ms\n",
            "Speed: 0.5ms preprocess, 31.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 backpacks, 4 handbags, 3 suitcases, 31.7ms\n",
            "Speed: 0.5ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 backpacks, 4 handbags, 2 suitcases, 30.7ms\n",
            "Speed: 0.4ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 4 handbags, 2 suitcases, 31.3ms\n",
            "Speed: 0.5ms preprocess, 31.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 3 handbags, 2 suitcases, 1 book, 31.9ms\n",
            "Speed: 0.5ms preprocess, 31.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 5 handbags, 3 suitcases, 1 book, 31.7ms\n",
            "Speed: 0.5ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 4 handbags, 3 suitcases, 1 book, 31.2ms\n",
            "Speed: 0.5ms preprocess, 31.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 5 handbags, 2 suitcases, 1 book, 31.2ms\n",
            "Speed: 0.5ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 backpacks, 4 handbags, 2 suitcases, 1 book, 34.2ms\n",
            "Speed: 0.5ms preprocess, 34.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 3 backpacks, 5 handbags, 2 suitcases, 1 book, 31.9ms\n",
            "Speed: 0.5ms preprocess, 31.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 backpacks, 4 handbags, 2 suitcases, 1 book, 31.0ms\n",
            "Speed: 0.5ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 backpacks, 4 handbags, 3 suitcases, 1 book, 30.8ms\n",
            "Speed: 0.5ms preprocess, 30.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 backpacks, 5 handbags, 3 suitcases, 1 book, 30.8ms\n",
            "Speed: 0.4ms preprocess, 30.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 backpacks, 5 handbags, 2 suitcases, 1 book, 30.8ms\n",
            "Speed: 0.5ms preprocess, 30.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 3 backpacks, 5 handbags, 2 suitcases, 1 book, 31.1ms\n",
            "Speed: 0.5ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 4 backpacks, 7 handbags, 3 suitcases, 1 book, 30.9ms\n",
            "Speed: 0.5ms preprocess, 30.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 backpacks, 6 handbags, 4 suitcases, 1 book, 32.0ms\n",
            "Speed: 0.5ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 3 handbags, 2 ties, 3 suitcases, 1 skateboard, 31.8ms\n",
            "Speed: 0.4ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 backpack, 2 handbags, 2 ties, 2 suitcases, 1 skateboard, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 2 handbags, 1 tie, 1 suitcase, 32.3ms\n",
            "Speed: 0.6ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 backpacks, 1 handbag, 1 tie, 1 suitcase, 31.3ms\n",
            "Speed: 9.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 backpack, 2 handbags, 1 tie, 1 suitcase, 30.8ms\n",
            "Speed: 0.5ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 3 handbags, 1 tie, 1 suitcase, 31.0ms\n",
            "Speed: 0.6ms preprocess, 31.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 1 backpack, 2 handbags, 2 ties, 1 suitcase, 31.4ms\n",
            "Speed: 0.6ms preprocess, 31.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 1 backpack, 3 handbags, 30.4ms\n",
            "Speed: 0.5ms preprocess, 30.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 2 backpacks, 3 handbags, 1 suitcase, 31.8ms\n",
            "Speed: 0.5ms preprocess, 31.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 backpack, 2 handbags, 3 suitcases, 31.6ms\n",
            "Speed: 0.6ms preprocess, 31.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 1 backpack, 2 handbags, 1 suitcase, 31.1ms\n",
            "Speed: 0.5ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 1 backpack, 2 handbags, 30.4ms\n",
            "Speed: 0.5ms preprocess, 30.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 backpack, 2 handbags, 1 tie, 1 suitcase, 1 cup, 31.6ms\n",
            "Speed: 0.5ms preprocess, 31.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 2 backpacks, 2 ties, 1 suitcase, 30.1ms\n",
            "Speed: 0.5ms preprocess, 30.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 1 backpack, 1 handbag, 1 tie, 2 suitcases, 31.8ms\n",
            "Speed: 0.6ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 2 backpacks, 3 handbags, 2 ties, 2 suitcases, 31.3ms\n",
            "Speed: 0.5ms preprocess, 31.3ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 2 ties, 1 suitcase, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 backpack, 1 handbag, 2 ties, 2 suitcases, 1 bottle, 36.6ms\n",
            "Speed: 0.5ms preprocess, 36.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 2 ties, 1 suitcase, 1 bottle, 38.4ms\n",
            "Speed: 0.5ms preprocess, 38.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 1 backpack, 2 ties, 1 bottle, 38.4ms\n",
            "Speed: 0.5ms preprocess, 38.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 backpack, 2 ties, 2 suitcases, 38.0ms\n",
            "Speed: 0.5ms preprocess, 38.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 1 backpack, 1 tie, 2 suitcases, 38.2ms\n",
            "Speed: 1.3ms preprocess, 38.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 backpack, 1 handbag, 1 tie, 2 suitcases, 1 bottle, 37.4ms\n",
            "Speed: 0.5ms preprocess, 37.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 handbag, 1 tie, 1 suitcase, 40.6ms\n",
            "Speed: 0.6ms preprocess, 40.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 4 handbags, 3 ties, 2 suitcases, 1 bottle, 38.8ms\n",
            "Speed: 0.4ms preprocess, 38.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 2 handbags, 3 ties, 2 suitcases, 1 bottle, 41.6ms\n",
            "Speed: 0.5ms preprocess, 41.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 2 handbags, 2 ties, 3 suitcases, 1 bottle, 38.6ms\n",
            "Speed: 0.5ms preprocess, 38.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 2 handbags, 2 ties, 3 suitcases, 38.5ms\n",
            "Speed: 0.5ms preprocess, 38.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 3 handbags, 1 tie, 3 suitcases, 1 bottle, 40.1ms\n",
            "Speed: 0.5ms preprocess, 40.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 2 handbags, 3 suitcases, 2 bottles, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 backpack, 1 handbag, 3 suitcases, 1 bottle, 41.2ms\n",
            "Speed: 0.5ms preprocess, 41.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 backpack, 3 handbags, 1 tie, 4 suitcases, 1 bottle, 46.4ms\n",
            "Speed: 0.5ms preprocess, 46.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 3 handbags, 2 ties, 4 suitcases, 42.2ms\n",
            "Speed: 0.5ms preprocess, 42.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 1 truck, 3 handbags, 2 ties, 3 suitcases, 2 bottles, 43.9ms\n",
            "Speed: 7.0ms preprocess, 43.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 1 truck, 2 handbags, 3 suitcases, 1 bottle, 44.0ms\n",
            "Speed: 0.5ms preprocess, 44.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 1 truck, 3 handbags, 2 ties, 3 suitcases, 1 bottle, 42.4ms\n",
            "Speed: 0.5ms preprocess, 42.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 cars, 3 handbags, 2 ties, 3 suitcases, 1 bottle, 44.3ms\n",
            "Speed: 0.5ms preprocess, 44.3ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 truck, 3 handbags, 1 tie, 3 suitcases, 42.6ms\n",
            "Speed: 0.5ms preprocess, 42.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 1 truck, 3 handbags, 1 tie, 2 suitcases, 43.3ms\n",
            "Speed: 0.5ms preprocess, 43.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 truck, 3 handbags, 2 ties, 2 suitcases, 41.9ms\n",
            "Speed: 0.6ms preprocess, 41.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 truck, 5 handbags, 2 suitcases, 1 skateboard, 42.0ms\n",
            "Speed: 0.5ms preprocess, 42.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 5 handbags, 2 suitcases, 42.9ms\n",
            "Speed: 0.5ms preprocess, 42.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 1 traffic light, 2 handbags, 1 tie, 41.9ms\n",
            "Speed: 0.5ms preprocess, 41.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 cars, 3 handbags, 2 ties, 1 skateboard, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 3 handbags, 1 tie, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 6 handbags, 1 tie, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 1 truck, 2 backpacks, 3 handbags, 1 tie, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 truck, 2 backpacks, 2 handbags, 1 tie, 39.4ms\n",
            "Speed: 0.6ms preprocess, 39.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 1 truck, 1 traffic light, 1 backpack, 1 tie, 39.5ms\n",
            "Speed: 1.2ms preprocess, 39.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 traffic light, 1 handbag, 2 ties, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 3 backpacks, 4 handbags, 1 tie, 39.9ms\n",
            "Speed: 0.5ms preprocess, 39.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 2 backpacks, 2 handbags, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 backpack, 3 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 2 backpacks, 3 handbags, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 2 backpacks, 4 handbags, 1 cell phone, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 2 backpacks, 3 handbags, 1 cell phone, 39.7ms\n",
            "Speed: 0.5ms preprocess, 39.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 backpack, 2 handbags, 1 cell phone, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 backpack, 3 handbags, 1 tie, 1 cell phone, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 1 backpack, 4 handbags, 39.7ms\n",
            "Speed: 0.5ms preprocess, 39.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 1 backpack, 4 handbags, 40.5ms\n",
            "Speed: 0.5ms preprocess, 40.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 backpack, 1 handbag, 42.1ms\n",
            "Speed: 1.6ms preprocess, 42.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 handbag, 40.9ms\n",
            "Speed: 0.7ms preprocess, 40.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 41.0ms\n",
            "Speed: 0.5ms preprocess, 41.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 40.0ms\n",
            "Speed: 0.5ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 37.5ms\n",
            "Speed: 0.5ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 41.4ms\n",
            "Speed: 0.5ms preprocess, 41.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 36.6ms\n",
            "Speed: 0.5ms preprocess, 36.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 handbag, 33.8ms\n",
            "Speed: 3.2ms preprocess, 33.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 1 backpack, 1 handbag, 34.1ms\n",
            "Speed: 0.8ms preprocess, 34.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 backpack, 1 handbag, 33.9ms\n",
            "Speed: 0.5ms preprocess, 33.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 3 backpacks, 3 handbags, 33.9ms\n",
            "Speed: 0.5ms preprocess, 33.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 2 backpacks, 3 handbags, 37.1ms\n",
            "Speed: 0.5ms preprocess, 37.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 backpack, 4 handbags, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 4 handbags, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 3 handbags, 1 tie, 34.3ms\n",
            "Speed: 0.7ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 4 handbags, 33.9ms\n",
            "Speed: 0.5ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 backpacks, 4 handbags, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 3 handbags, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bench, 1 backpack, 5 handbags, 1 cell phone, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 2 handbags, 1 cell phone, 36.0ms\n",
            "Speed: 0.5ms preprocess, 36.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 1 handbag, 1 suitcase, 34.8ms\n",
            "Speed: 0.5ms preprocess, 34.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 backpacks, 2 handbags, 1 tie, 1 suitcase, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 3 handbags, 1 suitcase, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 6 handbags, 1 tie, 1 suitcase, 38.6ms\n",
            "Speed: 0.6ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 7 handbags, 2 ties, 1 suitcase, 1 cell phone, 37.9ms\n",
            "Speed: 0.5ms preprocess, 37.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 5 handbags, 1 tie, 38.6ms\n",
            "Speed: 0.5ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bus, 2 backpacks, 5 handbags, 1 tie, 1 suitcase, 38.5ms\n",
            "Speed: 0.5ms preprocess, 38.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 7 handbags, 1 tie, 37.6ms\n",
            "Speed: 0.5ms preprocess, 37.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 7 handbags, 1 tie, 38.5ms\n",
            "Speed: 0.5ms preprocess, 38.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 5 handbags, 1 tie, 39.6ms\n",
            "Speed: 0.5ms preprocess, 39.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 5 handbags, 1 suitcase, 39.4ms\n",
            "Speed: 0.6ms preprocess, 39.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 backpack, 4 handbags, 1 suitcase, 1 remote, 1 cell phone, 38.0ms\n",
            "Speed: 0.9ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 backpack, 4 handbags, 1 suitcase, 1 cell phone, 37.7ms\n",
            "Speed: 0.5ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 5 handbags, 1 suitcase, 1 cell phone, 38.3ms\n",
            "Speed: 0.5ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 5 handbags, 1 suitcase, 37.4ms\n",
            "Speed: 0.5ms preprocess, 37.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 5 handbags, 1 suitcase, 1 cell phone, 36.6ms\n",
            "Speed: 0.4ms preprocess, 36.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 backpack, 4 handbags, 1 suitcase, 1 knife, 1 cell phone, 31.3ms\n",
            "Speed: 0.5ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 backpack, 5 handbags, 1 suitcase, 1 knife, 1 cell phone, 31.8ms\n",
            "Speed: 0.5ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 2 backpacks, 4 handbags, 1 suitcase, 1 cell phone, 32.2ms\n",
            "Speed: 0.5ms preprocess, 32.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 backpack, 4 handbags, 1 suitcase, 1 cell phone, 31.8ms\n",
            "Speed: 0.5ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 2 backpacks, 3 handbags, 1 suitcase, 31.2ms\n",
            "Speed: 0.5ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 backpack, 4 handbags, 1 suitcase, 2 cell phones, 32.3ms\n",
            "Speed: 0.4ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 backpack, 4 handbags, 1 suitcase, 2 cell phones, 36.7ms\n",
            "Speed: 0.5ms preprocess, 36.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 4 handbags, 1 suitcase, 33.5ms\n",
            "Speed: 0.5ms preprocess, 33.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 backpack, 6 handbags, 2 suitcases, 1 cell phone, 32.4ms\n",
            "Speed: 0.5ms preprocess, 32.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 backpack, 4 handbags, 2 suitcases, 2 cell phones, 34.8ms\n",
            "Speed: 0.6ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 backpack, 4 handbags, 1 suitcase, 1 cell phone, 32.2ms\n",
            "Speed: 0.5ms preprocess, 32.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 1 backpack, 4 handbags, 1 suitcase, 1 bottle, 1 cell phone, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 backpack, 4 handbags, 1 suitcase, 1 cell phone, 32.1ms\n",
            "Speed: 0.5ms preprocess, 32.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 backpack, 4 handbags, 1 suitcase, 1 cell phone, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 1 backpack, 4 handbags, 1 suitcase, 30.5ms\n",
            "Speed: 0.5ms preprocess, 30.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 4 handbags, 1 suitcase, 1 cell phone, 31.5ms\n",
            "Speed: 1.5ms preprocess, 31.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 5 handbags, 1 suitcase, 1 cell phone, 30.8ms\n",
            "Speed: 0.7ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 5 handbags, 1 suitcase, 1 cell phone, 31.9ms\n",
            "Speed: 1.8ms preprocess, 31.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 3 handbags, 1 suitcase, 1 cell phone, 31.6ms\n",
            "Speed: 0.5ms preprocess, 31.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 1 backpack, 4 handbags, 1 suitcase, 1 cell phone, 32.3ms\n",
            "Speed: 0.4ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 backpack, 4 handbags, 2 suitcases, 30.6ms\n",
            "Speed: 0.5ms preprocess, 30.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 1 backpack, 2 handbags, 2 suitcases, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 cars, 3 backpacks, 1 handbag, 1 suitcase, 32.6ms\n",
            "Speed: 0.6ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 2 backpacks, 2 handbags, 2 suitcases, 1 cell phone, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 2 backpacks, 3 handbags, 2 suitcases, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 2 backpacks, 1 handbag, 1 suitcase, 33.0ms\n",
            "Speed: 3.1ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 backpack, 2 handbags, 1 suitcase, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 1 handbag, 1 suitcase, 32.4ms\n",
            "Speed: 6.8ms preprocess, 32.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 cars, 1 umbrella, 1 handbag, 1 suitcase, 33.4ms\n",
            "Speed: 0.5ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 1 handbag, 1 suitcase, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 1 handbag, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 1 handbag, 32.1ms\n",
            "Speed: 0.4ms preprocess, 32.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 cars, 1 handbag, 32.2ms\n",
            "Speed: 0.5ms preprocess, 32.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 2 handbags, 1 suitcase, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 backpack, 1 handbag, 33.0ms\n",
            "Speed: 0.6ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 1 backpack, 1 handbag, 1 bottle, 38.3ms\n",
            "Speed: 0.5ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 1 handbag, 1 suitcase, 1 bottle, 31.2ms\n",
            "Speed: 0.5ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 1 handbag, 1 bottle, 32.0ms\n",
            "Speed: 0.5ms preprocess, 32.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 1 handbag, 1 suitcase, 34.5ms\n",
            "Speed: 0.5ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 1 handbag, 35.5ms\n",
            "Speed: 0.5ms preprocess, 35.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 1 handbag, 31.5ms\n",
            "Speed: 0.5ms preprocess, 31.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 1 backpack, 2 handbags, 31.2ms\n",
            "Speed: 0.6ms preprocess, 31.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 2 backpacks, 2 handbags, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 2 backpacks, 2 handbags, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 2 backpacks, 3 handbags, 32.1ms\n",
            "Speed: 0.5ms preprocess, 32.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 2 backpacks, 3 handbags, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 cars, 5 backpacks, 1 handbag, 32.1ms\n",
            "Speed: 0.5ms preprocess, 32.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 cars, 3 backpacks, 4 handbags, 32.9ms\n",
            "Speed: 0.6ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 3 backpacks, 4 handbags, 36.2ms\n",
            "Speed: 0.5ms preprocess, 36.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 3 backpacks, 3 handbags, 32.0ms\n",
            "Speed: 0.4ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 cars, 1 truck, 3 traffic lights, 1 handbag, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 cars, 1 truck, 3 traffic lights, 1 backpack, 2 handbags, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 cars, 1 truck, 3 traffic lights, 1 backpack, 2 handbags, 32.1ms\n",
            "Speed: 0.6ms preprocess, 32.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 cars, 1 truck, 3 traffic lights, 2 handbags, 33.6ms\n",
            "Speed: 0.5ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 cars, 1 truck, 3 traffic lights, 1 handbag, 34.9ms\n",
            "Speed: 0.5ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 cars, 1 truck, 3 traffic lights, 2 handbags, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 cars, 1 truck, 3 traffic lights, 1 handbag, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 cars, 1 truck, 4 traffic lights, 1 handbag, 32.1ms\n",
            "Speed: 0.5ms preprocess, 32.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 cars, 1 truck, 3 traffic lights, 1 handbag, 32.8ms\n",
            "Speed: 0.6ms preprocess, 32.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 cars, 1 truck, 3 traffic lights, 1 handbag, 32.6ms\n",
            "Speed: 2.7ms preprocess, 32.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 cars, 1 truck, 3 traffic lights, 1 handbag, 32.9ms\n",
            "Speed: 0.6ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 3 cars, 1 truck, 3 traffic lights, 1 handbag, 35.9ms\n",
            "Speed: 0.5ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 cars, 1 truck, 3 traffic lights, 1 handbag, 36.0ms\n",
            "Speed: 0.5ms preprocess, 36.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 cars, 1 truck, 2 traffic lights, 1 handbag, 36.6ms\n",
            "Speed: 0.5ms preprocess, 36.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 1 truck, 3 traffic lights, 1 handbag, 36.7ms\n",
            "Speed: 0.5ms preprocess, 36.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 cars, 1 truck, 3 traffic lights, 1 handbag, 35.9ms\n",
            "Speed: 0.6ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 cars, 1 truck, 3 traffic lights, 1 handbag, 36.7ms\n",
            "Speed: 0.6ms preprocess, 36.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 cars, 1 motorcycle, 1 truck, 3 traffic lights, 1 handbag, 35.7ms\n",
            "Speed: 1.9ms preprocess, 35.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 cars, 2 trucks, 3 traffic lights, 1 handbag, 34.6ms\n",
            "Speed: 0.6ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 cars, 1 truck, 3 traffic lights, 1 handbag, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 cars, 1 truck, 3 traffic lights, 1 handbag, 34.7ms\n",
            "Speed: 0.4ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 23 persons, 3 cars, 1 truck, 3 traffic lights, 2 handbags, 42.5ms\n",
            "Speed: 0.5ms preprocess, 42.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 4 cars, 1 truck, 3 traffic lights, 2 handbags, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 cars, 1 truck, 3 traffic lights, 1 handbag, 38.4ms\n",
            "Speed: 0.5ms preprocess, 38.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 22 persons, 3 cars, 1 truck, 3 traffic lights, 1 handbag, 34.8ms\n",
            "Speed: 0.5ms preprocess, 34.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 22 persons, 3 cars, 1 truck, 4 traffic lights, 2 handbags, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 24 persons, 3 cars, 1 truck, 4 traffic lights, 1 handbag, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 26 persons, 3 cars, 1 truck, 3 traffic lights, 1 handbag, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 26 persons, 3 cars, 3 traffic lights, 1 backpack, 1 handbag, 35.8ms\n",
            "Speed: 0.5ms preprocess, 35.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 25 persons, 4 cars, 1 truck, 3 traffic lights, 1 backpack, 1 handbag, 34.6ms\n",
            "Speed: 0.5ms preprocess, 34.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 24 persons, 3 cars, 1 truck, 3 traffic lights, 1 backpack, 1 handbag, 40.8ms\n",
            "Speed: 0.5ms preprocess, 40.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 cars, 1 truck, 3 traffic lights, 1 backpack, 1 handbag, 34.9ms\n",
            "Speed: 0.6ms preprocess, 34.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 3 traffic lights, 1 backpack, 2 handbags, 34.6ms\n",
            "Speed: 0.5ms preprocess, 34.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 1 bus, 2 traffic lights, 1 backpack, 2 handbags, 42.9ms\n",
            "Speed: 0.5ms preprocess, 42.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 1 bus, 4 traffic lights, 1 backpack, 1 handbag, 36.8ms\n",
            "Speed: 0.5ms preprocess, 36.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 2 traffic lights, 1 backpack, 2 handbags, 38.5ms\n",
            "Speed: 0.5ms preprocess, 38.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 car, 3 traffic lights, 1 backpack, 2 handbags, 37.5ms\n",
            "Speed: 0.5ms preprocess, 37.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 bus, 3 traffic lights, 1 backpack, 2 handbags, 39.3ms\n",
            "Speed: 0.5ms preprocess, 39.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 cars, 1 truck, 4 traffic lights, 1 backpack, 1 handbag, 37.8ms\n",
            "Speed: 0.5ms preprocess, 37.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 3 traffic lights, 1 backpack, 1 handbag, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 1 traffic light, 1 handbag, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 persons, 3 cars, 1 bus, 2 traffic lights, 39.3ms\n",
            "Speed: 0.5ms preprocess, 39.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 persons, 4 cars, 2 traffic lights, 39.3ms\n",
            "Speed: 0.6ms preprocess, 39.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 persons, 4 cars, 1 traffic light, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 traffic light, 39.3ms\n",
            "Speed: 0.5ms preprocess, 39.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 2 traffic lights, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 2 traffic lights, 39.2ms\n",
            "Speed: 0.5ms preprocess, 39.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 41.0ms\n",
            "Speed: 0.5ms preprocess, 41.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 2 traffic lights, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 2 traffic lights, 39.2ms\n",
            "Speed: 0.5ms preprocess, 39.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 2 traffic lights, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 2 traffic lights, 45.0ms\n",
            "Speed: 0.5ms preprocess, 45.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 2 traffic lights, 40.5ms\n",
            "Speed: 0.4ms preprocess, 40.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 traffic light, 42.1ms\n",
            "Speed: 0.5ms preprocess, 42.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 1 traffic light, 40.5ms\n",
            "Speed: 0.5ms preprocess, 40.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 traffic light, 41.5ms\n",
            "Speed: 0.5ms preprocess, 41.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 traffic light, 1 skateboard, 39.6ms\n",
            "Speed: 4.5ms preprocess, 39.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 2 traffic lights, 2 skateboards, 42.0ms\n",
            "Speed: 0.5ms preprocess, 42.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 2 traffic lights, 42.9ms\n",
            "Speed: 0.5ms preprocess, 42.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 1 motorcycle, 2 traffic lights, 39.0ms\n",
            "Speed: 1.4ms preprocess, 39.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 3 traffic lights, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 bicycle, 2 traffic lights, 40.3ms\n",
            "Speed: 0.6ms preprocess, 40.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 3 motorcycles, 2 traffic lights, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 traffic lights, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 bicycles, 4 traffic lights, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 1 bus, 3 traffic lights, 41.7ms\n",
            "Speed: 0.5ms preprocess, 41.7ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 3 traffic lights, 1 tv, 40.3ms\n",
            "Speed: 0.5ms preprocess, 40.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 1 car, 5 traffic lights, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 4 traffic lights, 1 backpack, 45.5ms\n",
            "Speed: 0.5ms preprocess, 45.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 3 traffic lights, 1 backpack, 43.4ms\n",
            "Speed: 0.5ms preprocess, 43.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 1 traffic light, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 3 traffic lights, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 3 traffic lights, 43.8ms\n",
            "Speed: 0.5ms preprocess, 43.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 1 bus, 4 traffic lights, 40.4ms\n",
            "Speed: 0.6ms preprocess, 40.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 2 traffic lights, 1 handbag, 41.1ms\n",
            "Speed: 0.5ms preprocess, 41.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 3 traffic lights, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 2 traffic lights, 1 handbag, 39.6ms\n",
            "Speed: 0.6ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 traffic lights, 1 handbag, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 3 traffic lights, 1 handbag, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 traffic lights, 1 backpack, 1 tie, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 1 backpack, 1 handbag, 39.7ms\n",
            "Speed: 0.5ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 traffic lights, 1 backpack, 2 handbags, 43.2ms\n",
            "Speed: 3.0ms preprocess, 43.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 traffic lights, 1 backpack, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 1 backpack, 1 tie, 39.5ms\n",
            "Speed: 0.4ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 traffic lights, 2 backpacks, 2 ties, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 traffic lights, 2 backpacks, 35.6ms\n",
            "Speed: 0.5ms preprocess, 35.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 1 backpack, 1 tie, 34.6ms\n",
            "Speed: 1.0ms preprocess, 34.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 2 traffic lights, 1 handbag, 35.3ms\n",
            "Speed: 0.8ms preprocess, 35.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 1 backpack, 1 handbag, 1 tie, 34.7ms\n",
            "Speed: 0.5ms preprocess, 34.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 traffic lights, 1 backpack, 38.0ms\n",
            "Speed: 0.5ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 traffic lights, 1 backpack, 1 tie, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 traffic lights, 1 backpack, 1 tv, 34.9ms\n",
            "Speed: 0.4ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 traffic lights, 1 backpack, 1 tie, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 traffic lights, 1 backpack, 1 tv, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 traffic lights, 1 tie, 1 tv, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 traffic lights, 1 backpack, 1 tie, 1 tv, 32.0ms\n",
            "Speed: 0.5ms preprocess, 32.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 traffic lights, 1 backpack, 1 handbag, 1 tie, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 traffic lights, 1 backpack, 1 tie, 1 skateboard, 1 tv, 31.7ms\n",
            "Speed: 0.5ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 traffic lights, 1 tie, 31.2ms\n",
            "Speed: 0.6ms preprocess, 31.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 backpack, 1 handbag, 1 tie, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 traffic light, 3 handbags, 1 tie, 1 cell phone, 31.5ms\n",
            "Speed: 0.5ms preprocess, 31.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 traffic light, 2 handbags, 1 tie, 1 cell phone, 32.0ms\n",
            "Speed: 0.5ms preprocess, 32.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 traffic lights, 1 backpack, 1 tie, 1 cell phone, 33.4ms\n",
            "Speed: 0.5ms preprocess, 33.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 1 backpack, 1 tie, 1 cell phone, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 2 backpacks, 1 handbag, 33.1ms\n",
            "Speed: 0.6ms preprocess, 33.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 traffic lights, 2 backpacks, 1 handbag, 1 tie, 1 cell phone, 35.6ms\n",
            "Speed: 0.6ms preprocess, 35.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 traffic lights, 1 backpack, 1 handbag, 1 tie, 33.2ms\n",
            "Speed: 0.5ms preprocess, 33.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 traffic lights, 1 backpack, 32.3ms\n",
            "Speed: 0.4ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 backpacks, 1 handbag, 1 tie, 33.5ms\n",
            "Speed: 0.5ms preprocess, 33.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 1 backpack, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 traffic light, 1 backpack, 1 handbag, 1 tie, 1 cell phone, 32.3ms\n",
            "Speed: 0.6ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 traffic lights, 1 backpack, 1 tie, 1 cell phone, 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 backpack, 1 tie, 2 cell phones, 33.2ms\n",
            "Speed: 0.5ms preprocess, 33.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 1 cell phone, 32.4ms\n",
            "Speed: 1.1ms preprocess, 32.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 1 backpack, 1 handbag, 1 tie, 55.6ms\n",
            "Speed: 0.5ms preprocess, 55.6ms inference, 16.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 1 backpack, 2 handbags, 1 tie, 1 cell phone, 50.1ms\n",
            "Speed: 0.5ms preprocess, 50.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 2 handbags, 2 cell phones, 31.9ms\n",
            "Speed: 2.1ms preprocess, 31.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 1 backpack, 1 tie, 2 cell phones, 33.3ms\n",
            "Speed: 0.5ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 traffic lights, 1 backpack, 1 handbag, 2 cell phones, 31.2ms\n",
            "Speed: 0.5ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 traffic light, 1 backpack, 1 handbag, 1 tie, 2 cell phones, 31.1ms\n",
            "Speed: 0.4ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 1 backpack, 2 cell phones, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 1 backpack, 1 handbag, 1 tie, 2 cell phones, 71.3ms\n",
            "Speed: 0.5ms preprocess, 71.3ms inference, 6.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 1 backpack, 2 handbags, 1 tie, 1 cell phone, 93.6ms\n",
            "Speed: 2.1ms preprocess, 93.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 1 backpack, 31.8ms\n",
            "Speed: 2.6ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 traffic light, 1 backpack, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 1 backpack, 1 tie, 37.9ms\n",
            "Speed: 0.5ms preprocess, 37.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 traffic lights, 1 backpack, 1 tie, 1 cell phone, 37.8ms\n",
            "Speed: 0.5ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 1 backpack, 1 tie, 38.5ms\n",
            "Speed: 0.5ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 traffic light, 1 backpack, 1 tie, 37.6ms\n",
            "Speed: 0.5ms preprocess, 37.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 traffic light, 1 backpack, 1 tie, 69.4ms\n",
            "Speed: 0.5ms preprocess, 69.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 traffic lights, 1 backpack, 1 tie, 1 tv, 56.2ms\n",
            "Speed: 0.6ms preprocess, 56.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 traffic light, 2 backpacks, 2 handbags, 1 tie, 1 tv, 41.0ms\n",
            "Speed: 0.5ms preprocess, 41.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 1 backpack, 1 handbag, 1 tie, 44.3ms\n",
            "Speed: 0.6ms preprocess, 44.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 1 backpack, 2 handbags, 1 tie, 41.6ms\n",
            "Speed: 0.5ms preprocess, 41.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 traffic light, 1 backpack, 1 handbag, 1 tie, 41.1ms\n",
            "Speed: 0.5ms preprocess, 41.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 1 backpack, 2 handbags, 1 tie, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 1 backpack, 2 handbags, 1 tie, 40.3ms\n",
            "Speed: 0.5ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 traffic lights, 1 backpack, 1 handbag, 39.7ms\n",
            "Speed: 0.5ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 traffic light, 2 backpacks, 1 handbag, 41.9ms\n",
            "Speed: 0.5ms preprocess, 41.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 traffic light, 2 backpacks, 2 handbags, 1 tie, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 traffic lights, 1 backpack, 1 handbag, 1 tie, 39.0ms\n",
            "Speed: 0.7ms preprocess, 39.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 traffic lights, 1 backpack, 1 handbag, 1 tie, 40.1ms\n",
            "Speed: 0.5ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 traffic lights, 2 backpacks, 1 handbag, 39.0ms\n",
            "Speed: 0.6ms preprocess, 39.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 traffic lights, 2 backpacks, 1 handbag, 1 tie, 39.2ms\n",
            "Speed: 3.0ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 traffic light, 1 backpack, 1 handbag, 1 tie, 1 cell phone, 40.0ms\n",
            "Speed: 0.6ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 1 backpack, 2 handbags, 2 ties, 1 cell phone, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 traffic light, 1 backpack, 3 handbags, 2 ties, 1 tv, 1 cell phone, 39.3ms\n",
            "Speed: 0.5ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 traffic lights, 1 backpack, 1 handbag, 1 tie, 39.1ms\n",
            "Speed: 0.6ms preprocess, 39.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 traffic lights, 2 backpacks, 3 handbags, 1 tie, 39.3ms\n",
            "Speed: 0.5ms preprocess, 39.3ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 traffic lights, 2 backpacks, 1 handbag, 1 tie, 42.7ms\n",
            "Speed: 0.5ms preprocess, 42.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 traffic light, 2 backpacks, 1 tie, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 traffic light, 2 backpacks, 1 handbag, 1 tie, 39.2ms\n",
            "Speed: 0.5ms preprocess, 39.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 traffic lights, 2 backpacks, 1 tie, 1 tv, 42.9ms\n",
            "Speed: 2.6ms preprocess, 42.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 traffic lights, 2 backpacks, 1 tie, 40.3ms\n",
            "Speed: 0.5ms preprocess, 40.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 traffic lights, 3 backpacks, 2 ties, 41.4ms\n",
            "Speed: 0.5ms preprocess, 41.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 traffic lights, 3 backpacks, 2 ties, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 backpacks, 1 handbag, 1 tie, 1 tv, 42.3ms\n",
            "Speed: 0.5ms preprocess, 42.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 traffic lights, 3 backpacks, 1 tie, 1 tv, 38.5ms\n",
            "Speed: 0.5ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 traffic lights, 3 backpacks, 1 handbag, 2 ties, 1 tv, 39.3ms\n",
            "Speed: 0.5ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 traffic lights, 2 backpacks, 1 tie, 37.7ms\n",
            "Speed: 1.5ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 traffic lights, 3 backpacks, 3 handbags, 2 ties, 37.9ms\n",
            "Speed: 0.5ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 traffic lights, 3 backpacks, 1 handbag, 2 ties, 43.8ms\n",
            "Speed: 0.5ms preprocess, 43.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 traffic light, 2 backpacks, 1 handbag, 2 ties, 1 tv, 37.8ms\n",
            "Speed: 0.6ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 2 backpacks, 1 handbag, 1 tie, 1 tv, 38.8ms\n",
            "Speed: 1.6ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 traffic lights, 2 backpacks, 1 handbag, 1 tv, 39.3ms\n",
            "Speed: 0.6ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 traffic light, 2 backpacks, 1 handbag, 2 ties, 39.3ms\n",
            "Speed: 0.5ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 2 backpacks, 1 handbag, 3 ties, 37.7ms\n",
            "Speed: 0.5ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 backpacks, 1 handbag, 41.9ms\n",
            "Speed: 0.5ms preprocess, 41.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 traffic lights, 3 backpacks, 1 handbag, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 traffic light, 3 backpacks, 1 handbag, 1 tie, 1 tv, 37.8ms\n",
            "Speed: 0.4ms preprocess, 37.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 3 backpacks, 2 handbags, 1 tv, 45.4ms\n",
            "Speed: 0.6ms preprocess, 45.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 2 backpacks, 2 handbags, 1 tv, 37.8ms\n",
            "Speed: 0.5ms preprocess, 37.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 traffic lights, 3 backpacks, 2 handbags, 39.8ms\n",
            "Speed: 0.6ms preprocess, 39.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 3 backpacks, 5 handbags, 1 suitcase, 37.8ms\n",
            "Speed: 0.5ms preprocess, 37.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 3 backpacks, 3 handbags, 38.2ms\n",
            "Speed: 0.5ms preprocess, 38.2ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 3 backpacks, 4 handbags, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 traffic light, 3 backpacks, 2 handbags, 45.2ms\n",
            "Speed: 0.5ms preprocess, 45.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 traffic lights, 3 backpacks, 4 handbags, 40.5ms\n",
            "Speed: 0.5ms preprocess, 40.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 traffic light, 3 backpacks, 3 handbags, 42.0ms\n",
            "Speed: 0.5ms preprocess, 42.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 traffic light, 4 backpacks, 3 handbags, 44.3ms\n",
            "Speed: 0.5ms preprocess, 44.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 traffic light, 4 backpacks, 5 handbags, 40.4ms\n",
            "Speed: 0.6ms preprocess, 40.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 traffic lights, 4 backpacks, 3 handbags, 1 tie, 40.0ms\n",
            "Speed: 0.5ms preprocess, 40.0ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bus, 1 traffic light, 3 backpacks, 3 handbags, 42.2ms\n",
            "Speed: 0.5ms preprocess, 42.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 traffic light, 4 backpacks, 4 handbags, 41.2ms\n",
            "Speed: 0.5ms preprocess, 41.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 3 backpacks, 4 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 traffic lights, 4 backpacks, 2 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 4 backpacks, 4 handbags, 49.4ms\n",
            "Speed: 0.5ms preprocess, 49.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 4 backpacks, 4 handbags, 39.7ms\n",
            "Speed: 0.5ms preprocess, 39.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 4 backpacks, 4 handbags, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 4 backpacks, 4 handbags, 2 ties, 41.7ms\n",
            "Speed: 0.5ms preprocess, 41.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 traffic lights, 4 backpacks, 3 handbags, 1 tie, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 4 backpacks, 4 handbags, 1 tie, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 traffic light, 4 backpacks, 4 handbags, 1 tie, 42.0ms\n",
            "Speed: 0.5ms preprocess, 42.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 traffic lights, 4 backpacks, 4 handbags, 1 tie, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 traffic light, 5 backpacks, 4 handbags, 1 tie, 41.2ms\n",
            "Speed: 0.6ms preprocess, 41.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 traffic lights, 4 backpacks, 4 handbags, 1 tie, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 5 backpacks, 5 handbags, 1 tie, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 traffic lights, 4 backpacks, 4 handbags, 1 tie, 40.1ms\n",
            "Speed: 0.6ms preprocess, 40.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 3 backpacks, 5 handbags, 1 tie, 41.4ms\n",
            "Speed: 0.7ms preprocess, 41.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 3 backpacks, 4 handbags, 1 tie, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 4 backpacks, 6 handbags, 1 tie, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 3 traffic lights, 3 backpacks, 6 handbags, 2 ties, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 traffic lights, 3 backpacks, 5 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 4 traffic lights, 3 backpacks, 5 handbags, 1 tie, 44.2ms\n",
            "Speed: 0.5ms preprocess, 44.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 traffic light, 3 backpacks, 6 handbags, 1 tie, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 3 traffic lights, 3 backpacks, 5 handbags, 1 tie, 39.6ms\n",
            "Speed: 0.6ms preprocess, 39.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 traffic lights, 4 backpacks, 5 handbags, 1 tie, 40.1ms\n",
            "Speed: 0.6ms preprocess, 40.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 traffic lights, 4 backpacks, 4 handbags, 1 tie, 41.3ms\n",
            "Speed: 0.5ms preprocess, 41.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 traffic lights, 4 backpacks, 4 handbags, 2 ties, 45.2ms\n",
            "Speed: 0.6ms preprocess, 45.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 traffic lights, 4 backpacks, 5 handbags, 2 ties, 45.0ms\n",
            "Speed: 0.6ms preprocess, 45.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 traffic lights, 4 backpacks, 5 handbags, 2 ties, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 traffic lights, 4 backpacks, 3 handbags, 1 tie, 42.1ms\n",
            "Speed: 0.8ms preprocess, 42.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 traffic lights, 6 backpacks, 5 handbags, 1 tie, 41.6ms\n",
            "Speed: 0.5ms preprocess, 41.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 4 backpacks, 5 handbags, 49.3ms\n",
            "Speed: 0.5ms preprocess, 49.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 4 backpacks, 5 handbags, 42.9ms\n",
            "Speed: 0.9ms preprocess, 42.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 4 traffic lights, 4 backpacks, 3 handbags, 44.2ms\n",
            "Speed: 0.5ms preprocess, 44.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 traffic lights, 5 backpacks, 3 handbags, 45.0ms\n",
            "Speed: 0.5ms preprocess, 45.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 4 traffic lights, 4 backpacks, 3 handbags, 1 tie, 45.3ms\n",
            "Speed: 0.5ms preprocess, 45.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 traffic light, 4 backpacks, 6 handbags, 43.7ms\n",
            "Speed: 0.5ms preprocess, 43.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 traffic lights, 2 backpacks, 4 handbags, 1 tie, 46.5ms\n",
            "Speed: 0.5ms preprocess, 46.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 3 backpacks, 6 handbags, 1 suitcase, 44.5ms\n",
            "Speed: 0.6ms preprocess, 44.5ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 3 backpacks, 5 handbags, 1 suitcase, 45.3ms\n",
            "Speed: 0.5ms preprocess, 45.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 5 cars, 2 buss, 2 trucks, 2 traffic lights, 2 backpacks, 4 handbags, 39.9ms\n",
            "Speed: 0.6ms preprocess, 39.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 5 cars, 1 bus, 2 trucks, 2 traffic lights, 2 backpacks, 3 handbags, 41.3ms\n",
            "Speed: 0.5ms preprocess, 41.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 4 cars, 2 buss, 2 trucks, 2 traffic lights, 2 backpacks, 3 handbags, 39.6ms\n",
            "Speed: 0.6ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 4 cars, 2 buss, 1 truck, 2 traffic lights, 2 backpacks, 2 handbags, 39.7ms\n",
            "Speed: 0.4ms preprocess, 39.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 5 cars, 2 buss, 2 trucks, 2 traffic lights, 2 backpacks, 2 handbags, 41.2ms\n",
            "Speed: 0.5ms preprocess, 41.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 4 cars, 2 buss, 2 trucks, 2 traffic lights, 2 backpacks, 3 handbags, 39.6ms\n",
            "Speed: 0.5ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 5 cars, 1 bus, 2 trucks, 2 traffic lights, 2 backpacks, 2 handbags, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 4 cars, 2 buss, 2 trucks, 2 traffic lights, 2 backpacks, 3 handbags, 39.7ms\n",
            "Speed: 0.4ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 4 cars, 1 bus, 2 trucks, 2 traffic lights, 1 backpack, 3 handbags, 39.7ms\n",
            "Speed: 0.5ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 4 cars, 1 bus, 1 truck, 2 traffic lights, 1 backpack, 2 handbags, 39.7ms\n",
            "Speed: 0.5ms preprocess, 39.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 1 bus, 2 trucks, 2 traffic lights, 1 backpack, 3 handbags, 39.6ms\n",
            "Speed: 0.4ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 5 cars, 1 bus, 2 trucks, 2 traffic lights, 1 backpack, 3 handbags, 39.6ms\n",
            "Speed: 0.8ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 6 cars, 2 buss, 2 trucks, 3 traffic lights, 1 backpack, 3 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 5 cars, 2 buss, 2 trucks, 2 traffic lights, 1 backpack, 2 handbags, 39.4ms\n",
            "Speed: 0.7ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 6 cars, 2 buss, 2 trucks, 2 traffic lights, 1 backpack, 3 handbags, 39.8ms\n",
            "Speed: 0.5ms preprocess, 39.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 6 cars, 2 buss, 2 trucks, 2 traffic lights, 1 backpack, 3 handbags, 39.7ms\n",
            "Speed: 0.5ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 6 cars, 2 buss, 2 trucks, 3 traffic lights, 1 backpack, 2 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 5 cars, 2 buss, 1 truck, 2 traffic lights, 1 backpack, 2 handbags, 39.7ms\n",
            "Speed: 0.5ms preprocess, 39.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 5 cars, 1 bus, 3 trucks, 3 traffic lights, 1 backpack, 2 handbags, 40.5ms\n",
            "Speed: 0.5ms preprocess, 40.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 1 bus, 2 trucks, 3 traffic lights, 1 backpack, 3 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 1 bus, 3 trucks, 2 traffic lights, 1 backpack, 5 handbags, 41.1ms\n",
            "Speed: 0.5ms preprocess, 41.1ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 2 buss, 2 trucks, 2 traffic lights, 1 backpack, 4 handbags, 40.8ms\n",
            "Speed: 0.5ms preprocess, 40.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 5 cars, 1 bus, 2 trucks, 2 traffic lights, 1 backpack, 5 handbags, 40.5ms\n",
            "Speed: 0.5ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 5 cars, 1 bus, 3 trucks, 3 traffic lights, 1 backpack, 5 handbags, 41.0ms\n",
            "Speed: 0.5ms preprocess, 41.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 6 cars, 1 bus, 3 trucks, 2 traffic lights, 2 backpacks, 3 handbags, 39.8ms\n",
            "Speed: 0.5ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 cars, 2 buss, 3 trucks, 2 traffic lights, 2 backpacks, 2 handbags, 43.5ms\n",
            "Speed: 0.5ms preprocess, 43.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 4 cars, 2 buss, 3 trucks, 2 traffic lights, 2 backpacks, 3 handbags, 39.6ms\n",
            "Speed: 0.5ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 4 cars, 2 buss, 2 trucks, 2 traffic lights, 2 backpacks, 3 handbags, 39.6ms\n",
            "Speed: 0.5ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 1 bus, 3 trucks, 2 traffic lights, 4 backpacks, 3 handbags, 39.6ms\n",
            "Speed: 1.1ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 2 buss, 2 trucks, 2 traffic lights, 2 backpacks, 3 handbags, 39.6ms\n",
            "Speed: 0.6ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 3 buss, 2 trucks, 3 traffic lights, 3 backpacks, 4 handbags, 39.7ms\n",
            "Speed: 0.6ms preprocess, 39.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 4 buss, 2 trucks, 2 traffic lights, 2 backpacks, 5 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 6 cars, 4 buss, 3 trucks, 2 traffic lights, 2 backpacks, 4 handbags, 39.9ms\n",
            "Speed: 0.5ms preprocess, 39.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 6 cars, 4 buss, 2 trucks, 2 traffic lights, 3 backpacks, 4 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 6 cars, 3 buss, 2 trucks, 2 traffic lights, 3 backpacks, 5 handbags, 39.7ms\n",
            "Speed: 0.6ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 6 cars, 2 buss, 2 trucks, 2 traffic lights, 3 backpacks, 5 handbags, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 5 cars, 2 buss, 2 trucks, 2 traffic lights, 3 backpacks, 4 handbags, 40.1ms\n",
            "Speed: 0.6ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 5 cars, 3 buss, 2 trucks, 2 traffic lights, 2 backpacks, 4 handbags, 38.7ms\n",
            "Speed: 0.5ms preprocess, 38.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 6 cars, 2 buss, 3 trucks, 2 traffic lights, 4 backpacks, 5 handbags, 38.6ms\n",
            "Speed: 0.5ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 5 cars, 4 buss, 1 truck, 2 traffic lights, 3 backpacks, 4 handbags, 38.6ms\n",
            "Speed: 0.5ms preprocess, 38.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 7 cars, 2 buss, 2 trucks, 2 traffic lights, 3 backpacks, 4 handbags, 38.6ms\n",
            "Speed: 0.4ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 5 cars, 3 buss, 2 trucks, 2 traffic lights, 3 backpacks, 5 handbags, 40.2ms\n",
            "Speed: 0.5ms preprocess, 40.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 cars, 2 buss, 3 trucks, 2 traffic lights, 2 backpacks, 4 handbags, 41.6ms\n",
            "Speed: 0.5ms preprocess, 41.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 3 buss, 3 trucks, 2 traffic lights, 3 backpacks, 4 handbags, 44.9ms\n",
            "Speed: 0.5ms preprocess, 44.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 cars, 4 buss, 3 trucks, 2 traffic lights, 3 backpacks, 4 handbags, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 5 cars, 4 buss, 3 trucks, 3 traffic lights, 3 backpacks, 4 handbags, 38.7ms\n",
            "Speed: 0.5ms preprocess, 38.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 4 cars, 3 buss, 3 trucks, 2 traffic lights, 3 backpacks, 5 handbags, 41.3ms\n",
            "Speed: 0.5ms preprocess, 41.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 5 cars, 5 buss, 3 trucks, 2 traffic lights, 3 backpacks, 4 handbags, 38.8ms\n",
            "Speed: 0.5ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 4 cars, 3 buss, 3 trucks, 2 traffic lights, 1 parking meter, 3 backpacks, 6 handbags, 38.8ms\n",
            "Speed: 0.5ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 5 cars, 3 buss, 3 trucks, 2 traffic lights, 1 parking meter, 3 backpacks, 4 handbags, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 5 cars, 4 buss, 2 trucks, 2 traffic lights, 3 backpacks, 4 handbags, 40.3ms\n",
            "Speed: 2.8ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 6 cars, 3 buss, 3 trucks, 2 traffic lights, 2 backpacks, 5 handbags, 38.8ms\n",
            "Speed: 0.5ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 6 cars, 4 buss, 3 trucks, 2 traffic lights, 2 backpacks, 4 handbags, 38.7ms\n",
            "Speed: 0.5ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 5 cars, 5 buss, 2 trucks, 2 traffic lights, 2 backpacks, 3 handbags, 40.9ms\n",
            "Speed: 0.6ms preprocess, 40.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 cars, 4 buss, 2 trucks, 2 traffic lights, 4 backpacks, 3 handbags, 40.1ms\n",
            "Speed: 0.6ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 cars, 3 buss, 3 trucks, 2 traffic lights, 4 backpacks, 3 handbags, 41.0ms\n",
            "Speed: 0.5ms preprocess, 41.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 cars, 5 buss, 3 trucks, 2 traffic lights, 4 backpacks, 3 handbags, 39.9ms\n",
            "Speed: 0.6ms preprocess, 39.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 5 cars, 4 buss, 1 truck, 2 traffic lights, 4 backpacks, 4 handbags, 39.6ms\n",
            "Speed: 0.5ms preprocess, 39.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 4 cars, 3 buss, 2 trucks, 2 traffic lights, 4 backpacks, 4 handbags, 40.9ms\n",
            "Speed: 0.5ms preprocess, 40.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 4 cars, 4 buss, 2 trucks, 2 traffic lights, 3 backpacks, 4 handbags, 43.7ms\n",
            "Speed: 0.5ms preprocess, 43.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 cars, 3 buss, 2 trucks, 2 traffic lights, 4 backpacks, 3 handbags, 39.7ms\n",
            "Speed: 0.5ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 3 buss, 3 trucks, 2 traffic lights, 3 backpacks, 4 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 5 cars, 3 buss, 2 trucks, 2 traffic lights, 4 backpacks, 4 handbags, 39.6ms\n",
            "Speed: 0.5ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 cars, 3 buss, 2 trucks, 2 traffic lights, 1 parking meter, 4 backpacks, 4 handbags, 39.7ms\n",
            "Speed: 0.5ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 6 cars, 2 buss, 2 trucks, 2 traffic lights, 4 backpacks, 5 handbags, 43.8ms\n",
            "Speed: 0.6ms preprocess, 43.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 6 cars, 3 buss, 2 trucks, 2 traffic lights, 4 backpacks, 5 handbags, 39.9ms\n",
            "Speed: 0.5ms preprocess, 39.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 5 cars, 3 buss, 3 trucks, 2 traffic lights, 3 backpacks, 4 handbags, 40.1ms\n",
            "Speed: 0.6ms preprocess, 40.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 cars, 4 buss, 3 trucks, 3 traffic lights, 4 backpacks, 4 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 cars, 3 buss, 1 truck, 2 traffic lights, 3 backpacks, 5 handbags, 39.7ms\n",
            "Speed: 0.5ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 4 cars, 2 buss, 2 trucks, 2 traffic lights, 4 backpacks, 4 handbags, 39.6ms\n",
            "Speed: 0.5ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 4 cars, 3 buss, 2 trucks, 3 traffic lights, 4 backpacks, 4 handbags, 38.2ms\n",
            "Speed: 0.5ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 4 cars, 3 buss, 1 truck, 2 traffic lights, 4 backpacks, 5 handbags, 36.5ms\n",
            "Speed: 0.5ms preprocess, 36.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 5 cars, 4 buss, 1 truck, 2 traffic lights, 3 backpacks, 5 handbags, 36.7ms\n",
            "Speed: 0.7ms preprocess, 36.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 6 cars, 4 buss, 2 trucks, 2 traffic lights, 3 backpacks, 4 handbags, 1 cell phone, 36.6ms\n",
            "Speed: 0.6ms preprocess, 36.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 6 cars, 4 buss, 1 truck, 3 traffic lights, 2 backpacks, 4 handbags, 36.7ms\n",
            "Speed: 0.5ms preprocess, 36.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 5 cars, 2 buss, 2 trucks, 4 traffic lights, 2 backpacks, 5 handbags, 37.2ms\n",
            "Speed: 0.5ms preprocess, 37.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 5 cars, 3 buss, 1 truck, 3 traffic lights, 4 backpacks, 4 handbags, 38.0ms\n",
            "Speed: 0.5ms preprocess, 38.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 4 cars, 2 buss, 3 trucks, 3 traffic lights, 3 backpacks, 4 handbags, 36.8ms\n",
            "Speed: 0.5ms preprocess, 36.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 4 cars, 3 buss, 2 trucks, 3 traffic lights, 3 backpacks, 4 handbags, 38.5ms\n",
            "Speed: 0.5ms preprocess, 38.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 2 buss, 2 trucks, 4 traffic lights, 5 backpacks, 4 handbags, 36.1ms\n",
            "Speed: 0.6ms preprocess, 36.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 2 buss, 2 trucks, 3 traffic lights, 2 backpacks, 4 handbags, 37.3ms\n",
            "Speed: 0.6ms preprocess, 37.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 1 bus, 2 trucks, 4 traffic lights, 3 backpacks, 5 handbags, 36.9ms\n",
            "Speed: 0.5ms preprocess, 36.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 1 bus, 2 trucks, 4 traffic lights, 4 backpacks, 5 handbags, 37.5ms\n",
            "Speed: 0.5ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 4 cars, 2 buss, 2 trucks, 4 traffic lights, 3 backpacks, 5 handbags, 35.6ms\n",
            "Speed: 0.5ms preprocess, 35.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 persons, 5 cars, 1 backpack, 2 handbags, 36.0ms\n",
            "Speed: 0.5ms preprocess, 36.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 1 truck, 1 backpack, 2 handbags, 35.4ms\n",
            "Speed: 1.0ms preprocess, 35.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 persons, 7 cars, 1 truck, 1 traffic light, 1 backpack, 2 handbags, 35.3ms\n",
            "Speed: 0.5ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 truck, 1 traffic light, 1 backpack, 2 handbags, 34.2ms\n",
            "Speed: 0.8ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 1 truck, 1 traffic light, 1 backpack, 1 handbag, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 1 truck, 1 traffic light, 1 backpack, 2 handbags, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 truck, 1 traffic light, 1 backpack, 2 handbags, 34.1ms\n",
            "Speed: 0.6ms preprocess, 34.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 truck, 1 traffic light, 1 backpack, 1 handbag, 37.7ms\n",
            "Speed: 2.1ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 truck, 2 traffic lights, 1 backpack, 2 handbags, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 truck, 2 traffic lights, 2 handbags, 37.4ms\n",
            "Speed: 0.5ms preprocess, 37.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 truck, 1 traffic light, 1 backpack, 1 handbag, 34.2ms\n",
            "Speed: 0.5ms preprocess, 34.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 1 truck, 1 traffic light, 2 backpacks, 2 handbags, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 truck, 2 backpacks, 1 handbag, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 truck, 2 backpacks, 2 handbags, 35.1ms\n",
            "Speed: 0.6ms preprocess, 35.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 truck, 2 backpacks, 1 handbag, 36.5ms\n",
            "Speed: 0.5ms preprocess, 36.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 truck, 2 backpacks, 1 handbag, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 1 truck, 2 backpacks, 1 handbag, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 truck, 2 traffic lights, 2 backpacks, 1 handbag, 34.7ms\n",
            "Speed: 0.5ms preprocess, 34.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 1 truck, 2 traffic lights, 2 backpacks, 1 handbag, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 cars, 1 truck, 1 traffic light, 2 backpacks, 1 handbag, 34.2ms\n",
            "Speed: 0.5ms preprocess, 34.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 1 truck, 1 traffic light, 2 backpacks, 1 handbag, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 truck, 1 traffic light, 2 backpacks, 1 handbag, 39.0ms\n",
            "Speed: 0.6ms preprocess, 39.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 truck, 1 traffic light, 2 backpacks, 1 handbag, 39.3ms\n",
            "Speed: 0.5ms preprocess, 39.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 1 truck, 2 traffic lights, 1 backpack, 1 handbag, 37.7ms\n",
            "Speed: 0.5ms preprocess, 37.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 truck, 1 backpack, 1 handbag, 40.7ms\n",
            "Speed: 0.5ms preprocess, 40.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 1 truck, 1 backpack, 1 handbag, 40.2ms\n",
            "Speed: 0.5ms preprocess, 40.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 1 truck, 2 traffic lights, 1 backpack, 1 handbag, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 1 truck, 2 traffic lights, 1 backpack, 1 handbag, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 1 truck, 1 traffic light, 1 backpack, 1 handbag, 40.2ms\n",
            "Speed: 0.5ms preprocess, 40.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 1 truck, 1 traffic light, 1 backpack, 1 handbag, 41.0ms\n",
            "Speed: 0.5ms preprocess, 41.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 1 truck, 2 traffic lights, 1 backpack, 1 handbag, 41.3ms\n",
            "Speed: 0.5ms preprocess, 41.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 1 truck, 1 backpack, 1 handbag, 1 cell phone, 40.6ms\n",
            "Speed: 0.5ms preprocess, 40.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 1 truck, 1 backpack, 1 handbag, 1 cell phone, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 truck, 1 backpack, 1 handbag, 1 cell phone, 43.0ms\n",
            "Speed: 0.5ms preprocess, 43.0ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 cars, 1 truck, 1 traffic light, 1 backpack, 1 handbag, 1 cell phone, 40.9ms\n",
            "Speed: 0.5ms preprocess, 40.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 cars, 1 truck, 1 traffic light, 1 backpack, 1 handbag, 1 cell phone, 40.0ms\n",
            "Speed: 0.5ms preprocess, 40.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 truck, 1 traffic light, 1 backpack, 1 handbag, 1 cell phone, 39.6ms\n",
            "Speed: 0.5ms preprocess, 39.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 truck, 1 traffic light, 1 backpack, 1 handbag, 1 cell phone, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 truck, 1 traffic light, 1 backpack, 1 handbag, 1 cell phone, 39.4ms\n",
            "Speed: 0.4ms preprocess, 39.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 1 truck, 1 backpack, 1 handbag, 2 cell phones, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 cars, 1 truck, 1 traffic light, 1 backpack, 1 handbag, 1 cell phone, 40.9ms\n",
            "Speed: 0.5ms preprocess, 40.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 3 cars, 1 truck, 1 traffic light, 1 backpack, 1 handbag, 1 cell phone, 40.1ms\n",
            "Speed: 0.5ms preprocess, 40.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 3 cars, 1 truck, 2 traffic lights, 1 backpack, 1 handbag, 1 cell phone, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 traffic light, 1 backpack, 2 handbags, 1 cell phone, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 bicycles, 2 cars, 1 traffic light, 1 backpack, 1 handbag, 2 cell phones, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 cars, 1 traffic light, 1 backpack, 2 handbags, 2 cell phones, 39.4ms\n",
            "Speed: 0.4ms preprocess, 39.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 4 cars, 2 traffic lights, 1 backpack, 3 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 traffic light, 1 backpack, 3 handbags, 43.3ms\n",
            "Speed: 0.5ms preprocess, 43.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 2 traffic lights, 1 backpack, 2 handbags, 1 cell phone, 44.4ms\n",
            "Speed: 0.6ms preprocess, 44.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 cars, 2 traffic lights, 2 backpacks, 2 handbags, 1 cell phone, 40.3ms\n",
            "Speed: 0.5ms preprocess, 40.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 traffic light, 1 backpack, 2 handbags, 1 tv, 3 cell phones, 42.0ms\n",
            "Speed: 0.5ms preprocess, 42.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 traffic light, 1 backpack, 2 handbags, 1 cell phone, 49.3ms\n",
            "Speed: 0.5ms preprocess, 49.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 2 traffic lights, 1 backpack, 2 handbags, 1 tv, 1 cell phone, 47.2ms\n",
            "Speed: 0.5ms preprocess, 47.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 1 traffic light, 1 backpack, 2 handbags, 1 tv, 1 cell phone, 39.9ms\n",
            "Speed: 0.5ms preprocess, 39.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 2 traffic lights, 1 backpack, 2 handbags, 1 tv, 1 cell phone, 40.3ms\n",
            "Speed: 0.5ms preprocess, 40.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 bus, 1 traffic light, 1 backpack, 2 handbags, 1 tv, 1 cell phone, 41.4ms\n",
            "Speed: 0.5ms preprocess, 41.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 1 bus, 1 truck, 1 traffic light, 1 backpack, 2 handbags, 1 tv, 1 cell phone, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 truck, 1 backpack, 2 handbags, 1 tv, 1 cell phone, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 1 truck, 1 backpack, 2 handbags, 1 tv, 1 cell phone, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 truck, 1 traffic light, 2 backpacks, 2 handbags, 1 tv, 1 cell phone, 43.2ms\n",
            "Speed: 0.5ms preprocess, 43.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 truck, 2 traffic lights, 2 backpacks, 2 handbags, 1 tv, 1 cell phone, 40.3ms\n",
            "Speed: 0.5ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 1 truck, 1 traffic light, 2 backpacks, 2 handbags, 1 cell phone, 40.0ms\n",
            "Speed: 0.5ms preprocess, 40.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 truck, 1 traffic light, 2 backpacks, 2 handbags, 1 tv, 1 cell phone, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 cars, 1 traffic light, 2 backpacks, 2 handbags, 1 tv, 1 cell phone, 39.4ms\n",
            "Speed: 0.4ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 cars, 1 traffic light, 2 backpacks, 1 handbag, 39.5ms\n",
            "Speed: 0.7ms preprocess, 39.5ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 cars, 2 traffic lights, 2 backpacks, 1 handbag, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 bus, 1 truck, 2 traffic lights, 2 backpacks, 1 handbag, 1 cell phone, 39.4ms\n",
            "Speed: 0.9ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 2 cars, 1 bus, 1 traffic light, 2 backpacks, 1 handbag, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 traffic light, 2 backpacks, 1 handbag, 38.9ms\n",
            "Speed: 0.5ms preprocess, 38.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 1 traffic light, 2 backpacks, 1 handbag, 38.0ms\n",
            "Speed: 0.6ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 traffic light, 1 backpack, 1 handbag, 37.5ms\n",
            "Speed: 0.4ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 traffic light, 1 backpack, 1 handbag, 1 tv, 36.7ms\n",
            "Speed: 0.5ms preprocess, 36.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 traffic light, 1 backpack, 2 handbags, 36.6ms\n",
            "Speed: 0.5ms preprocess, 36.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 traffic light, 1 backpack, 2 handbags, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 traffic light, 1 backpack, 2 handbags, 1 cell phone, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 2 traffic lights, 1 backpack, 2 handbags, 1 tv, 1 cell phone, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 backpack, 3 handbags, 1 tv, 2 cell phones, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 cars, 1 truck, 4 backpacks, 1 handbag, 1 tv, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 cars, 1 truck, 4 backpacks, 1 handbag, 1 tv, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 cars, 1 truck, 4 backpacks, 1 handbag, 33.6ms\n",
            "Speed: 0.5ms preprocess, 33.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 5 cars, 1 truck, 1 traffic light, 3 backpacks, 1 handbag, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 5 cars, 1 truck, 3 backpacks, 1 handbag, 33.9ms\n",
            "Speed: 0.5ms preprocess, 33.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 5 cars, 1 truck, 3 backpacks, 1 handbag, 37.1ms\n",
            "Speed: 0.5ms preprocess, 37.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 5 cars, 1 truck, 3 backpacks, 1 handbag, 33.8ms\n",
            "Speed: 0.6ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 1 truck, 1 traffic light, 3 backpacks, 1 handbag, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 1 truck, 3 backpacks, 2 handbags, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 cars, 1 truck, 3 backpacks, 1 handbag, 32.4ms\n",
            "Speed: 0.5ms preprocess, 32.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 truck, 3 backpacks, 2 handbags, 32.2ms\n",
            "Speed: 0.4ms preprocess, 32.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 truck, 3 backpacks, 2 handbags, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 truck, 1 traffic light, 3 backpacks, 1 handbag, 33.0ms\n",
            "Speed: 1.9ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 truck, 1 traffic light, 2 backpacks, 2 handbags, 38.4ms\n",
            "Speed: 0.5ms preprocess, 38.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 truck, 2 backpacks, 2 handbags, 32.7ms\n",
            "Speed: 1.1ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 2 backpacks, 2 handbags, 33.3ms\n",
            "Speed: 0.5ms preprocess, 33.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 truck, 1 backpack, 2 handbags, 32.4ms\n",
            "Speed: 3.2ms preprocess, 32.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 1 truck, 1 backpack, 1 handbag, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 truck, 1 backpack, 3 handbags, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 truck, 2 backpacks, 2 handbags, 34.2ms\n",
            "Speed: 1.1ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 truck, 2 backpacks, 3 handbags, 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 truck, 1 traffic light, 3 backpacks, 2 handbags, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 cars, 1 truck, 1 traffic light, 3 backpacks, 1 handbag, 33.0ms\n",
            "Speed: 0.8ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 cars, 1 truck, 2 traffic lights, 3 backpacks, 1 handbag, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 truck, 1 traffic light, 3 backpacks, 32.1ms\n",
            "Speed: 0.6ms preprocess, 32.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 cars, 1 truck, 2 traffic lights, 3 backpacks, 33.1ms\n",
            "Speed: 0.9ms preprocess, 33.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 cars, 1 truck, 4 backpacks, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 1 truck, 4 backpacks, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 3 cars, 5 backpacks, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 4 cars, 1 truck, 5 backpacks, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 4 cars, 4 backpacks, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 2 cars, 2 trucks, 3 backpacks, 34.9ms\n",
            "Speed: 0.8ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 2 cars, 1 truck, 3 backpacks, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 3 cars, 2 trucks, 3 backpacks, 34.2ms\n",
            "Speed: 0.5ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 2 trucks, 1 traffic light, 4 backpacks, 34.6ms\n",
            "Speed: 0.5ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 4 cars, 2 trucks, 3 backpacks, 34.5ms\n",
            "Speed: 0.5ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 cars, 1 traffic light, 4 backpacks, 34.9ms\n",
            "Speed: 0.5ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 cars, 2 trucks, 4 backpacks, 37.8ms\n",
            "Speed: 0.5ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 cars, 1 truck, 1 traffic light, 5 backpacks, 34.7ms\n",
            "Speed: 0.5ms preprocess, 34.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 4 cars, 1 truck, 4 backpacks, 36.7ms\n",
            "Speed: 0.5ms preprocess, 36.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 4 cars, 1 truck, 5 backpacks, 41.7ms\n",
            "Speed: 0.5ms preprocess, 41.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 bicycle, 4 cars, 1 truck, 1 traffic light, 5 backpacks, 34.8ms\n",
            "Speed: 0.5ms preprocess, 34.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 4 cars, 1 truck, 2 traffic lights, 5 backpacks, 35.5ms\n",
            "Speed: 0.8ms preprocess, 35.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 4 cars, 1 truck, 2 traffic lights, 5 backpacks, 1 handbag, 34.5ms\n",
            "Speed: 0.5ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 4 cars, 1 truck, 1 traffic light, 4 backpacks, 34.9ms\n",
            "Speed: 7.2ms preprocess, 34.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 4 cars, 1 truck, 2 traffic lights, 6 backpacks, 37.2ms\n",
            "Speed: 0.5ms preprocess, 37.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 4 cars, 1 truck, 1 traffic light, 5 backpacks, 39.7ms\n",
            "Speed: 2.6ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 4 cars, 1 truck, 1 traffic light, 5 backpacks, 40.1ms\n",
            "Speed: 0.6ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 4 cars, 1 truck, 5 backpacks, 38.9ms\n",
            "Speed: 3.3ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 5 cars, 1 truck, 4 backpacks, 39.0ms\n",
            "Speed: 0.9ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 bicycles, 6 cars, 1 truck, 5 backpacks, 1 handbag, 38.8ms\n",
            "Speed: 0.6ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 bicycles, 5 cars, 1 truck, 2 traffic lights, 5 backpacks, 38.6ms\n",
            "Speed: 0.5ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 5 cars, 1 truck, 1 traffic light, 5 backpacks, 41.7ms\n",
            "Speed: 0.5ms preprocess, 41.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 bicycle, 6 cars, 1 truck, 5 backpacks, 40.3ms\n",
            "Speed: 0.5ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 bicycles, 5 cars, 1 truck, 4 backpacks, 38.6ms\n",
            "Speed: 0.5ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 bicycle, 5 cars, 2 trucks, 4 backpacks, 40.3ms\n",
            "Speed: 0.5ms preprocess, 40.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 bicycles, 5 cars, 2 trucks, 1 traffic light, 5 backpacks, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 bicycle, 5 cars, 1 truck, 1 traffic light, 4 backpacks, 39.8ms\n",
            "Speed: 0.5ms preprocess, 39.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 5 cars, 1 truck, 1 traffic light, 5 backpacks, 1 handbag, 40.6ms\n",
            "Speed: 0.5ms preprocess, 40.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 6 cars, 2 trucks, 2 traffic lights, 5 backpacks, 39.2ms\n",
            "Speed: 0.5ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 6 cars, 2 trucks, 2 traffic lights, 6 backpacks, 39.7ms\n",
            "Speed: 2.5ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 5 cars, 1 truck, 2 traffic lights, 4 backpacks, 1 handbag, 42.5ms\n",
            "Speed: 0.5ms preprocess, 42.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 5 cars, 1 truck, 2 traffic lights, 4 backpacks, 2 handbags, 40.6ms\n",
            "Speed: 0.5ms preprocess, 40.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 5 cars, 1 truck, 2 traffic lights, 4 backpacks, 1 handbag, 40.7ms\n",
            "Speed: 2.3ms preprocess, 40.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 5 cars, 1 truck, 1 traffic light, 4 backpacks, 1 handbag, 39.9ms\n",
            "Speed: 0.5ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 5 cars, 2 trucks, 4 backpacks, 1 handbag, 39.9ms\n",
            "Speed: 0.4ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 4 cars, 1 truck, 4 backpacks, 2 handbags, 40.8ms\n",
            "Speed: 0.5ms preprocess, 40.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 5 cars, 1 truck, 1 traffic light, 4 backpacks, 41.4ms\n",
            "Speed: 0.5ms preprocess, 41.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 4 cars, 1 truck, 4 backpacks, 2 handbags, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 6 cars, 1 truck, 5 backpacks, 1 tv, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 8 cars, 1 truck, 1 traffic light, 6 backpacks, 1 book, 42.3ms\n",
            "Speed: 0.5ms preprocess, 42.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 6 cars, 1 truck, 5 backpacks, 1 handbag, 1 book, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 6 cars, 1 truck, 4 backpacks, 3 handbags, 41.1ms\n",
            "Speed: 0.5ms preprocess, 41.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 cars, 2 buss, 1 traffic light, 4 backpacks, 6 handbags, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 cars, 1 bus, 1 traffic light, 3 backpacks, 6 handbags, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 bus, 1 traffic light, 2 backpacks, 6 handbags, 1 tie, 39.3ms\n",
            "Speed: 0.5ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 bus, 1 traffic light, 3 backpacks, 7 handbags, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 4 cars, 1 bus, 2 traffic lights, 3 backpacks, 7 handbags, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 4 cars, 1 bus, 2 traffic lights, 1 backpack, 6 handbags, 39.2ms\n",
            "Speed: 0.5ms preprocess, 39.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 4 cars, 1 bus, 2 traffic lights, 2 backpacks, 9 handbags, 39.2ms\n",
            "Speed: 0.5ms preprocess, 39.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 4 cars, 1 bus, 2 traffic lights, 3 backpacks, 8 handbags, 40.3ms\n",
            "Speed: 0.5ms preprocess, 40.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 3 cars, 1 bus, 1 traffic light, 2 backpacks, 11 handbags, 1 tie, 39.4ms\n",
            "Speed: 0.7ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 4 cars, 1 bus, 2 traffic lights, 2 backpacks, 8 handbags, 2 ties, 39.2ms\n",
            "Speed: 0.6ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 5 cars, 1 bus, 2 traffic lights, 2 backpacks, 8 handbags, 1 tie, 39.1ms\n",
            "Speed: 0.7ms preprocess, 39.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 3 cars, 2 buss, 2 traffic lights, 3 backpacks, 7 handbags, 3 ties, 39.1ms\n",
            "Speed: 0.6ms preprocess, 39.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 3 cars, 1 bus, 2 traffic lights, 3 backpacks, 9 handbags, 2 ties, 46.1ms\n",
            "Speed: 0.5ms preprocess, 46.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 5 cars, 1 bus, 3 traffic lights, 2 backpacks, 8 handbags, 2 ties, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 6.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 4 cars, 1 bus, 5 traffic lights, 3 backpacks, 8 handbags, 1 tie, 39.1ms\n",
            "Speed: 0.6ms preprocess, 39.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 4 cars, 1 bus, 2 traffic lights, 2 backpacks, 9 handbags, 1 tie, 39.9ms\n",
            "Speed: 0.6ms preprocess, 39.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 5 cars, 2 buss, 1 traffic light, 3 backpacks, 8 handbags, 1 tie, 1 cell phone, 51.2ms\n",
            "Speed: 0.5ms preprocess, 51.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 5 cars, 2 buss, 1 traffic light, 3 backpacks, 8 handbags, 2 ties, 1 cell phone, 45.5ms\n",
            "Speed: 0.5ms preprocess, 45.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 6 cars, 1 bus, 3 traffic lights, 3 backpacks, 8 handbags, 2 ties, 1 cell phone, 42.4ms\n",
            "Speed: 0.5ms preprocess, 42.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 7 cars, 1 bus, 1 traffic light, 4 backpacks, 8 handbags, 1 tie, 1 cell phone, 43.8ms\n",
            "Speed: 1.2ms preprocess, 43.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 6 cars, 1 bus, 4 backpacks, 9 handbags, 1 cell phone, 47.1ms\n",
            "Speed: 0.5ms preprocess, 47.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 8 cars, 1 bus, 5 backpacks, 8 handbags, 41.7ms\n",
            "Speed: 0.5ms preprocess, 41.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 6 cars, 1 bus, 1 traffic light, 5 backpacks, 8 handbags, 1 cell phone, 45.0ms\n",
            "Speed: 0.5ms preprocess, 45.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 6 cars, 1 bus, 1 truck, 1 traffic light, 4 backpacks, 9 handbags, 1 cell phone, 41.7ms\n",
            "Speed: 0.5ms preprocess, 41.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 6 cars, 1 bus, 3 backpacks, 9 handbags, 1 cell phone, 41.8ms\n",
            "Speed: 4.9ms preprocess, 41.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 6 cars, 1 bus, 2 traffic lights, 3 backpacks, 9 handbags, 1 cell phone, 41.1ms\n",
            "Speed: 0.5ms preprocess, 41.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 4 cars, 1 bus, 1 traffic light, 3 backpacks, 10 handbags, 2 cell phones, 41.7ms\n",
            "Speed: 0.5ms preprocess, 41.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 6 cars, 1 bus, 1 backpack, 9 handbags, 1 cell phone, 43.1ms\n",
            "Speed: 0.5ms preprocess, 43.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 6 cars, 1 bus, 3 backpacks, 9 handbags, 1 cell phone, 40.9ms\n",
            "Speed: 0.5ms preprocess, 40.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 7 cars, 1 bus, 3 backpacks, 7 handbags, 2 cell phones, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 7 cars, 1 bus, 3 backpacks, 7 handbags, 2 cell phones, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 5 cars, 1 bus, 4 backpacks, 8 handbags, 1 cell phone, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 6 cars, 1 bus, 4 backpacks, 10 handbags, 1 cell phone, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 7 cars, 1 bus, 6 backpacks, 8 handbags, 1 cell phone, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 5 cars, 1 bus, 4 backpacks, 8 handbags, 2 cell phones, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 4 cars, 1 bus, 3 backpacks, 8 handbags, 2 cell phones, 41.0ms\n",
            "Speed: 0.5ms preprocess, 41.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 5 cars, 1 bus, 4 backpacks, 11 handbags, 1 cell phone, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 5 cars, 1 bus, 1 traffic light, 4 backpacks, 9 handbags, 1 cell phone, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 bus, 1 traffic light, 4 backpacks, 7 handbags, 1 cell phone, 40.5ms\n",
            "Speed: 0.5ms preprocess, 40.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 1 bus, 3 backpacks, 8 handbags, 1 cell phone, 44.1ms\n",
            "Speed: 0.5ms preprocess, 44.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 bus, 1 traffic light, 3 backpacks, 8 handbags, 1 cell phone, 41.0ms\n",
            "Speed: 0.7ms preprocess, 41.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 bus, 3 backpacks, 7 handbags, 1 cell phone, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 bus, 3 backpacks, 6 handbags, 1 cell phone, 42.9ms\n",
            "Speed: 0.5ms preprocess, 42.9ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 bus, 2 traffic lights, 3 backpacks, 4 handbags, 1 cell phone, 43.6ms\n",
            "Speed: 0.5ms preprocess, 43.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 bus, 2 traffic lights, 5 backpacks, 4 handbags, 1 cell phone, 47.9ms\n",
            "Speed: 0.5ms preprocess, 47.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 1 bus, 1 traffic light, 4 backpacks, 4 handbags, 1 cup, 1 cell phone, 39.9ms\n",
            "Speed: 0.5ms preprocess, 39.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 cars, 1 bus, 1 traffic light, 3 backpacks, 6 handbags, 1 cell phone, 41.6ms\n",
            "Speed: 0.5ms preprocess, 41.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 bus, 2 traffic lights, 2 backpacks, 6 handbags, 2 cups, 1 cell phone, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 1 bus, 3 traffic lights, 2 backpacks, 7 handbags, 1 cup, 1 cell phone, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 bus, 2 traffic lights, 3 backpacks, 8 handbags, 1 cell phone, 42.7ms\n",
            "Speed: 0.5ms preprocess, 42.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 bus, 1 traffic light, 2 backpacks, 7 handbags, 1 cup, 1 cell phone, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 bus, 1 traffic light, 2 backpacks, 9 handbags, 2 cups, 1 cell phone, 41.2ms\n",
            "Speed: 0.5ms preprocess, 41.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 bus, 2 backpacks, 6 handbags, 1 tie, 1 suitcase, 2 cups, 1 cell phone, 42.5ms\n",
            "Speed: 0.5ms preprocess, 42.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 bus, 1 traffic light, 7 handbags, 1 tie, 1 cup, 1 cell phone, 40.9ms\n",
            "Speed: 0.6ms preprocess, 40.9ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 cars, 1 bus, 2 traffic lights, 10 handbags, 41.5ms\n",
            "Speed: 0.5ms preprocess, 41.5ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 bus, 3 traffic lights, 1 backpack, 6 handbags, 1 tie, 1 wine glass, 39.9ms\n",
            "Speed: 0.6ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 cars, 1 bus, 3 traffic lights, 6 handbags, 1 tie, 1 cup, 41.6ms\n",
            "Speed: 0.4ms preprocess, 41.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 1 bus, 3 traffic lights, 6 handbags, 1 cup, 39.7ms\n",
            "Speed: 0.6ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 cars, 1 bus, 2 traffic lights, 5 handbags, 1 cup, 39.6ms\n",
            "Speed: 0.5ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 cars, 1 bus, 1 traffic light, 6 handbags, 1 cup, 41.4ms\n",
            "Speed: 0.6ms preprocess, 41.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 cars, 1 bus, 2 traffic lights, 5 handbags, 1 cup, 41.3ms\n",
            "Speed: 0.5ms preprocess, 41.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 bus, 4 traffic lights, 5 handbags, 1 cup, 42.2ms\n",
            "Speed: 0.5ms preprocess, 42.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 bus, 1 traffic light, 4 handbags, 1 tie, 1 cup, 41.0ms\n",
            "Speed: 0.5ms preprocess, 41.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 bus, 4 traffic lights, 5 handbags, 1 cup, 42.2ms\n",
            "Speed: 0.5ms preprocess, 42.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 bus, 3 traffic lights, 5 handbags, 42.6ms\n",
            "Speed: 0.5ms preprocess, 42.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 bus, 3 traffic lights, 6 handbags, 1 cup, 40.4ms\n",
            "Speed: 0.9ms preprocess, 40.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 cars, 1 bus, 3 traffic lights, 4 handbags, 1 cup, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bus, 3 traffic lights, 6 handbags, 1 cup, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 1 bus, 2 traffic lights, 6 handbags, 1 cup, 39.2ms\n",
            "Speed: 0.5ms preprocess, 39.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 bus, 1 truck, 1 traffic light, 7 handbags, 1 cup, 41.1ms\n",
            "Speed: 0.6ms preprocess, 41.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 1 bus, 1 truck, 3 traffic lights, 1 backpack, 4 handbags, 1 cup, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 1 bus, 3 traffic lights, 5 handbags, 1 cup, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 1 bus, 4 traffic lights, 1 backpack, 5 handbags, 1 cup, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 2 buss, 2 traffic lights, 5 handbags, 1 cup, 39.6ms\n",
            "Speed: 0.5ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 1 bus, 2 traffic lights, 5 handbags, 1 cup, 39.1ms\n",
            "Speed: 0.5ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 1 bus, 3 traffic lights, 4 handbags, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 1 bus, 1 traffic light, 1 backpack, 3 handbags, 39.0ms\n",
            "Speed: 0.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 1 bus, 1 traffic light, 1 handbag, 1 cup, 39.2ms\n",
            "Speed: 0.6ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 1 bus, 1 traffic light, 3 handbags, 1 cup, 38.6ms\n",
            "Speed: 0.5ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 1 bus, 2 traffic lights, 5 handbags, 2 cups, 37.8ms\n",
            "Speed: 0.5ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 1 bus, 3 traffic lights, 4 handbags, 2 cups, 38.0ms\n",
            "Speed: 0.5ms preprocess, 38.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 1 bus, 2 traffic lights, 4 handbags, 1 tie, 2 cups, 35.9ms\n",
            "Speed: 0.5ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 1 bus, 5 traffic lights, 3 handbags, 1 cup, 34.6ms\n",
            "Speed: 0.5ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 traffic light, 5 backpacks, 2 handbags, 34.6ms\n",
            "Speed: 0.5ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 traffic light, 6 backpacks, 3 handbags, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 traffic light, 5 backpacks, 2 handbags, 34.5ms\n",
            "Speed: 0.5ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 6 backpacks, 3 handbags, 34.4ms\n",
            "Speed: 0.6ms preprocess, 34.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 6 backpacks, 4 handbags, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 6 backpacks, 3 handbags, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 traffic light, 5 backpacks, 2 handbags, 34.0ms\n",
            "Speed: 0.6ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 traffic light, 5 backpacks, 5 handbags, 34.8ms\n",
            "Speed: 0.5ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 6 backpacks, 5 handbags, 38.4ms\n",
            "Speed: 0.5ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 4 backpacks, 4 handbags, 33.9ms\n",
            "Speed: 0.4ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 traffic light, 4 backpacks, 3 handbags, 36.6ms\n",
            "Speed: 0.5ms preprocess, 36.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 5 backpacks, 2 handbags, 33.6ms\n",
            "Speed: 0.6ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 5 backpacks, 3 handbags, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 5 backpacks, 4 handbags, 33.5ms\n",
            "Speed: 0.5ms preprocess, 33.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 4 backpacks, 4 handbags, 33.1ms\n",
            "Speed: 0.4ms preprocess, 33.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 4 backpacks, 4 handbags, 33.4ms\n",
            "Speed: 0.7ms preprocess, 33.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 4 backpacks, 3 handbags, 36.3ms\n",
            "Speed: 2.1ms preprocess, 36.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 5 backpacks, 3 handbags, 37.2ms\n",
            "Speed: 0.5ms preprocess, 37.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 4 backpacks, 2 handbags, 35.1ms\n",
            "Speed: 0.5ms preprocess, 35.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 5 backpacks, 2 handbags, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 1 traffic light, 4 backpacks, 3 handbags, 33.3ms\n",
            "Speed: 0.5ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 1 traffic light, 4 backpacks, 2 handbags, 33.4ms\n",
            "Speed: 0.6ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 traffic light, 7 backpacks, 1 handbag, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 traffic light, 8 backpacks, 3 handbags, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 6 backpacks, 3 handbags, 37.4ms\n",
            "Speed: 0.5ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 truck, 6 backpacks, 5 handbags, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 truck, 5 backpacks, 4 handbags, 38.5ms\n",
            "Speed: 0.7ms preprocess, 38.5ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 truck, 7 backpacks, 5 handbags, 38.1ms\n",
            "Speed: 0.5ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 7 backpacks, 5 handbags, 34.2ms\n",
            "Speed: 0.5ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 truck, 7 backpacks, 4 handbags, 37.4ms\n",
            "Speed: 0.5ms preprocess, 37.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 7 backpacks, 3 handbags, 34.0ms\n",
            "Speed: 0.6ms preprocess, 34.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 truck, 1 traffic light, 6 backpacks, 2 handbags, 34.9ms\n",
            "Speed: 0.5ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 cars, 1 truck, 1 traffic light, 5 backpacks, 3 handbags, 33.5ms\n",
            "Speed: 0.8ms preprocess, 33.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 truck, 1 traffic light, 4 backpacks, 3 handbags, 35.9ms\n",
            "Speed: 0.5ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 truck, 1 traffic light, 5 backpacks, 4 handbags, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 truck, 1 traffic light, 5 backpacks, 4 handbags, 33.9ms\n",
            "Speed: 0.5ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 cars, 1 truck, 1 traffic light, 4 backpacks, 5 handbags, 33.4ms\n",
            "Speed: 2.4ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 1 truck, 1 traffic light, 5 backpacks, 5 handbags, 33.9ms\n",
            "Speed: 0.5ms preprocess, 33.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 truck, 1 traffic light, 4 backpacks, 5 handbags, 36.2ms\n",
            "Speed: 0.5ms preprocess, 36.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 cars, 1 truck, 4 backpacks, 6 handbags, 33.4ms\n",
            "Speed: 0.5ms preprocess, 33.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 cars, 1 truck, 5 backpacks, 6 handbags, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 cars, 1 truck, 7 backpacks, 6 handbags, 34.2ms\n",
            "Speed: 0.5ms preprocess, 34.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 2 trucks, 6 backpacks, 6 handbags, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 1 truck, 6 backpacks, 7 handbags, 1 potted plant, 33.9ms\n",
            "Speed: 0.5ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 truck, 4 backpacks, 6 handbags, 1 potted plant, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 truck, 5 backpacks, 6 handbags, 1 suitcase, 1 potted plant, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 truck, 4 backpacks, 6 handbags, 1 suitcase, 33.9ms\n",
            "Speed: 0.5ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 1 truck, 3 backpacks, 7 handbags, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 car, 2 trucks, 5 backpacks, 6 handbags, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 2 trucks, 4 backpacks, 6 handbags, 33.4ms\n",
            "Speed: 1.4ms preprocess, 33.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 trucks, 4 backpacks, 8 handbags, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 trucks, 4 backpacks, 5 handbags, 1 suitcase, 33.9ms\n",
            "Speed: 0.6ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 trucks, 5 backpacks, 5 handbags, 36.4ms\n",
            "Speed: 0.5ms preprocess, 36.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 trucks, 5 backpacks, 4 handbags, 1 suitcase, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 trucks, 5 backpacks, 5 handbags, 1 suitcase, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 1 truck, 2 traffic lights, 3 handbags, 1 cup, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 1 cell phone, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 33.6ms\n",
            "Speed: 0.5ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 24 persons, 3 cars, 1 traffic light, 3 handbags, 1 cup, 33.5ms\n",
            "Speed: 0.5ms preprocess, 33.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 4 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 33.6ms\n",
            "Speed: 0.6ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 4 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 33.6ms\n",
            "Speed: 0.5ms preprocess, 33.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 4 cars, 1 truck, 1 traffic light, 3 handbags, 33.1ms\n",
            "Speed: 0.6ms preprocess, 33.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 4 cars, 1 traffic light, 3 handbags, 1 cup, 35.7ms\n",
            "Speed: 0.5ms preprocess, 35.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 cars, 1 traffic light, 3 handbags, 1 cup, 39.4ms\n",
            "Speed: 0.6ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 cars, 1 traffic light, 3 handbags, 35.6ms\n",
            "Speed: 2.7ms preprocess, 35.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 4 cars, 2 traffic lights, 3 handbags, 1 cup, 37.6ms\n",
            "Speed: 0.5ms preprocess, 37.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 cars, 2 traffic lights, 3 handbags, 1 cup, 36.6ms\n",
            "Speed: 0.5ms preprocess, 36.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 2 traffic lights, 3 handbags, 1 cup, 36.4ms\n",
            "Speed: 0.5ms preprocess, 36.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 4 cars, 2 traffic lights, 3 handbags, 1 cup, 36.7ms\n",
            "Speed: 0.5ms preprocess, 36.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 6 cars, 1 truck, 2 traffic lights, 3 handbags, 36.6ms\n",
            "Speed: 0.6ms preprocess, 36.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 4 cars, 2 trucks, 2 traffic lights, 3 handbags, 38.2ms\n",
            "Speed: 0.5ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 cars, 1 truck, 2 traffic lights, 3 handbags, 36.9ms\n",
            "Speed: 0.5ms preprocess, 36.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 1 truck, 2 traffic lights, 3 handbags, 35.9ms\n",
            "Speed: 0.5ms preprocess, 35.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 cars, 1 truck, 2 traffic lights, 3 handbags, 1 cup, 34.8ms\n",
            "Speed: 0.5ms preprocess, 34.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 cars, 1 truck, 1 traffic light, 3 handbags, 37.0ms\n",
            "Speed: 0.6ms preprocess, 37.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 36.3ms\n",
            "Speed: 0.5ms preprocess, 36.3ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 35.8ms\n",
            "Speed: 0.6ms preprocess, 35.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 37.3ms\n",
            "Speed: 0.6ms preprocess, 37.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 36.7ms\n",
            "Speed: 0.5ms preprocess, 36.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 50.7ms\n",
            "Speed: 0.5ms preprocess, 50.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 39.9ms\n",
            "Speed: 0.5ms preprocess, 39.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 41.0ms\n",
            "Speed: 0.5ms preprocess, 41.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 38.4ms\n",
            "Speed: 0.5ms preprocess, 38.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 1 truck, 3 handbags, 1 cup, 34.6ms\n",
            "Speed: 0.7ms preprocess, 34.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 1 truck, 3 handbags, 1 cup, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 cars, 1 truck, 3 handbags, 1 cup, 35.6ms\n",
            "Speed: 0.5ms preprocess, 35.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 21 persons, 3 cars, 1 truck, 4 handbags, 1 cup, 36.3ms\n",
            "Speed: 0.5ms preprocess, 36.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 22 persons, 4 cars, 1 truck, 1 traffic light, 4 handbags, 1 cup, 36.3ms\n",
            "Speed: 0.5ms preprocess, 36.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 22 persons, 5 cars, 1 truck, 1 traffic light, 4 handbags, 1 cup, 41.6ms\n",
            "Speed: 0.5ms preprocess, 41.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 23 persons, 4 cars, 1 traffic light, 4 handbags, 1 cup, 41.3ms\n",
            "Speed: 0.5ms preprocess, 41.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 20 persons, 5 cars, 1 traffic light, 4 handbags, 1 cup, 38.6ms\n",
            "Speed: 0.6ms preprocess, 38.6ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 17 persons, 4 cars, 1 traffic light, 4 handbags, 1 cup, 46.1ms\n",
            "Speed: 0.6ms preprocess, 46.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 cars, 1 traffic light, 3 handbags, 1 cup, 41.6ms\n",
            "Speed: 0.5ms preprocess, 41.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 cars, 1 traffic light, 4 handbags, 1 cup, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 cars, 2 traffic lights, 3 handbags, 1 cup, 40.5ms\n",
            "Speed: 0.4ms preprocess, 40.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 2 traffic lights, 3 handbags, 1 cup, 40.7ms\n",
            "Speed: 0.4ms preprocess, 40.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 2 traffic lights, 3 handbags, 1 cup, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 cars, 2 traffic lights, 3 handbags, 1 cup, 41.3ms\n",
            "Speed: 0.4ms preprocess, 41.3ms inference, 6.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 2 traffic lights, 3 handbags, 1 cup, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 cars, 1 truck, 2 traffic lights, 3 handbags, 1 cup, 39.8ms\n",
            "Speed: 3.3ms preprocess, 39.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 persons, 4 cars, 1 truck, 2 traffic lights, 4 handbags, 1 cup, 40.5ms\n",
            "Speed: 0.5ms preprocess, 40.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 truck, 2 traffic lights, 3 handbags, 1 cup, 39.9ms\n",
            "Speed: 0.5ms preprocess, 39.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 39.4ms\n",
            "Speed: 0.6ms preprocess, 39.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 41.4ms\n",
            "Speed: 0.5ms preprocess, 41.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 45.0ms\n",
            "Speed: 0.5ms preprocess, 45.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 cars, 1 truck, 1 traffic light, 3 handbags, 2 cups, 40.4ms\n",
            "Speed: 0.5ms preprocess, 40.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 cars, 1 truck, 1 traffic light, 3 handbags, 1 cup, 41.8ms\n",
            "Speed: 0.6ms preprocess, 41.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.7ms\n",
            "Speed: 0.5ms preprocess, 40.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.5ms\n",
            "Speed: 0.5ms preprocess, 42.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.1ms\n",
            "Speed: 0.5ms preprocess, 42.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 38.7ms\n",
            "Speed: 0.6ms preprocess, 38.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 36.0ms\n",
            "Speed: 0.6ms preprocess, 36.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 36.1ms\n",
            "Speed: 0.5ms preprocess, 36.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 33.2ms\n",
            "Speed: 0.5ms preprocess, 33.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 34.9ms\n",
            "Speed: 0.5ms preprocess, 34.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 33.5ms\n",
            "Speed: 0.5ms preprocess, 33.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.7ms\n",
            "Speed: 0.5ms preprocess, 31.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 30.9ms\n",
            "Speed: 0.5ms preprocess, 30.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 30.9ms\n",
            "Speed: 0.5ms preprocess, 30.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.2ms\n",
            "Speed: 0.4ms preprocess, 32.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.7ms\n",
            "Speed: 0.4ms preprocess, 31.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.6ms\n",
            "Speed: 0.5ms preprocess, 31.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.9ms\n",
            "Speed: 0.5ms preprocess, 31.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 33.5ms\n",
            "Speed: 0.5ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 34.2ms\n",
            "Speed: 0.5ms preprocess, 34.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 36.6ms\n",
            "Speed: 0.5ms preprocess, 36.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.3ms\n",
            "Speed: 0.5ms preprocess, 31.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.5ms\n",
            "Speed: 1.2ms preprocess, 32.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 33.1ms\n",
            "Speed: 1.4ms preprocess, 33.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 30.4ms\n",
            "Speed: 0.5ms preprocess, 30.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.3ms\n",
            "Speed: 0.4ms preprocess, 31.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 30.9ms\n",
            "Speed: 0.5ms preprocess, 30.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.0ms\n",
            "Speed: 0.5ms preprocess, 31.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.0ms\n",
            "Speed: 1.0ms preprocess, 32.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.1ms\n",
            "Speed: 0.4ms preprocess, 32.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.6ms\n",
            "Speed: 1.3ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.1ms\n",
            "Speed: 0.4ms preprocess, 31.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.9ms\n",
            "Speed: 0.8ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.8ms\n",
            "Speed: 0.4ms preprocess, 31.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.8ms\n",
            "Speed: 0.5ms preprocess, 31.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.5ms\n",
            "Speed: 0.5ms preprocess, 31.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.0ms\n",
            "Speed: 0.5ms preprocess, 32.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.6ms\n",
            "Speed: 0.4ms preprocess, 32.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 33.1ms\n",
            "Speed: 0.6ms preprocess, 33.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.9ms\n",
            "Speed: 0.5ms preprocess, 31.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.5ms\n",
            "Speed: 0.6ms preprocess, 32.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.2ms\n",
            "Speed: 0.5ms preprocess, 31.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.4ms\n",
            "Speed: 0.5ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.6ms\n",
            "Speed: 0.4ms preprocess, 31.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.7ms\n",
            "Speed: 0.6ms preprocess, 32.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.9ms\n",
            "Speed: 0.6ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.2ms\n",
            "Speed: 0.5ms preprocess, 32.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.9ms\n",
            "Speed: 0.9ms preprocess, 31.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.4ms\n",
            "Speed: 0.5ms preprocess, 32.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.2ms\n",
            "Speed: 0.5ms preprocess, 31.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    }
  ]
}